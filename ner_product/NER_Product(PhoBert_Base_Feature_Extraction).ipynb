{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_Product(PhoBert_Base_Feature_Extraction).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hqFZ9S8iYjAt",
        "DrQh9wLOfJpC",
        "jMlEkVv_qP3N",
        "iKGguI5MwRQX",
        "hhXBySlHfyJm",
        "rk60B5uRZLw6",
        "C2HOIe277Vly"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqFZ9S8iYjAt",
        "colab_type": "text"
      },
      "source": [
        "#Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTpTqgffYdFj",
        "colab_type": "code",
        "outputId": "12a886f5-bdae-4a09-b979-4537258de813",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        }
      },
      "source": [
        "!pip install transformers==2.6.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/a0/32e3a4501ef480f7ea01aac329a716132f32f7911ef1c2fac228acc57ca7/transformers-2.6.0-py3-none-any.whl (540kB)\n",
            "\r\u001b[K     |▋                               | 10kB 26.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 6.2MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30kB 8.7MB/s eta 0:00:01\r\u001b[K     |██▍                             | 40kB 7.9MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 6.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 61kB 7.5MB/s eta 0:00:01\r\u001b[K     |████▎                           | 71kB 8.1MB/s eta 0:00:01\r\u001b[K     |████▉                           | 81kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 92kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 102kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 112kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 122kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 133kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 143kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 153kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 163kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 174kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 184kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 194kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 204kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 215kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 225kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 235kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 245kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 256kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 266kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 276kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 286kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 296kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 307kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 317kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 327kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 337kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 348kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 358kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 368kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 378kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 389kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 399kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 409kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 419kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 430kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 440kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 450kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 460kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 471kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 481kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 491kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 501kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 512kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 522kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 532kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 542kB 8.6MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/88/49e772d686088e1278766ad68a463513642a2a877487decbd691dec02955/sentencepiece-0.1.90-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 28.8MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 36.9MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 44.5MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 28.4MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 29.6MB/s eta 0:00:01\r\u001b[K     |█▉                              | 61kB 32.4MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 21.7MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 23.5MB/s eta 0:00:01\r\u001b[K     |██▊                             | 92kB 25.4MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 23.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 112kB 23.8MB/s eta 0:00:01\r\u001b[K     |███▊                            | 122kB 23.8MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 23.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 143kB 23.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 153kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 174kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 184kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 194kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 204kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 215kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 225kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 235kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 245kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 256kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 266kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 276kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 286kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 296kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 307kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 317kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 327kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 337kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 348kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 358kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 368kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 378kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 389kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 399kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 409kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 419kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 430kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 440kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 450kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 460kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 471kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 481kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 491kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 501kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 512kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 522kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 532kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 542kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 552kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 563kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 573kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 583kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 593kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 604kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 614kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 624kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 634kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 645kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 655kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 665kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 675kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 686kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 696kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 706kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 716kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 727kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 737kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 747kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 757kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 768kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 778kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 788kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 798kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 808kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 819kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 829kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 839kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 849kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 860kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 870kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 880kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 890kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 901kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 911kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 921kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 931kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 942kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 952kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 962kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 972kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 983kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 993kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.0MB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.0MB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.0MB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.0MB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1MB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1MB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 23.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (1.18.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (2019.12.20)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 49.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (1.13.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 53.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (4.41.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.6.0) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.6.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.6.0) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.6.0) (3.0.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.6.0) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.6.0) (1.16.4)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.6.0) (0.9.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.6.0) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.6.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.6.0) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.4->boto3->transformers==2.6.0) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.4->boto3->transformers==2.6.0) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=10f679cec6ba7256be42fbca98c047715d7bddc041f614ffe5a541426c471811\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.90 tokenizers-0.5.2 transformers-2.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egqq-nMHYtDG",
        "colab_type": "code",
        "outputId": "33e4942c-525e-41dc-e820-402a54fe8f78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "!pip install fairseq"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fairseq\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/bf/de299e082e7af010d35162cb9a185dc6c17db71624590f2f379aeb2519ff/fairseq-0.9.0.tar.gz (306kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.17)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.18.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq) (2019.12.20)\n",
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/9d/9846507837ca50ae20917f59d83b79246b8313bd19d4f5bf575ecb98132b/sacrebleu-1.4.9-py3-none-any.whl (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.5.0+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq) (4.41.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.20)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu->fairseq) (3.6.6)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (0.16.0)\n",
            "Building wheels for collected packages: fairseq\n",
            "  Building wheel for fairseq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.9.0-cp36-cp36m-linux_x86_64.whl size=2035346 sha256=2f7874511b5b89a6c2a07325026682b1c762ae62ff87d8316baaced74d5e9d62\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/3e/1b/0fa30695dcba41e4b0088067fa40f3328d1e8ee78c22cd4766\n",
            "Successfully built fairseq\n",
            "Installing collected packages: portalocker, sacrebleu, fairseq\n",
            "Successfully installed fairseq-0.9.0 portalocker-1.7.0 sacrebleu-1.4.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxPmfRKEYvWM",
        "colab_type": "code",
        "outputId": "9664f72f-1685-4d7e-b758-b29dbabb99a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "!pip install fastBPE"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastBPE\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/37/f97181428a5d151501b90b2cebedf97c81b034ace753606a3cda5ad4e6e2/fastBPE-0.1.0.tar.gz\n",
            "Building wheels for collected packages: fastBPE\n",
            "  Building wheel for fastBPE (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastBPE: filename=fastBPE-0.1.0-cp36-cp36m-linux_x86_64.whl size=479270 sha256=bd9941fd1595ee7bd2210118bffffa366e9f2fe97fda5c175c83faa9bcd30097\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/0c/9c/fc62058b4d473a5602bcd3d3edfece796f123875379ea82d79\n",
            "Successfully built fastBPE\n",
            "Installing collected packages: fastBPE\n",
            "Successfully installed fastBPE-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZBCwr9NdWhS",
        "colab_type": "code",
        "outputId": "1df24a7b-20d0-4e53-bda7-430017209ee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.4)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=bdc54cad614a54107868724e1476f29c8ce9d60bc215ba355fd7b18dbbc55065\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-0.0.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6xCcDtbY3f0",
        "colab_type": "code",
        "outputId": "a78d8337-cc9f-4392-e0ad-2947ccef5d1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "import argparse\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import transformers\n",
        "import pandas as pd\n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, RandomSampler, TensorDataset, SequentialSampler\n",
        "\n",
        "from fairseq.data.encoders.fastbpe import fastBPE\n",
        "from fairseq.data import Dictionary\n",
        "\n",
        "from transformers import RobertaConfig, RobertaModel\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.notebook import trange\n",
        "from seqeval.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHPeu0KffDOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 60\n",
        "batch_sz = 16\n",
        "epochs = 5\n",
        "max_grad_norm = 1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TpMivmBw95V",
        "colab_type": "code",
        "outputId": "47f3e3a6-9faa-4068-a8ba-f6b9d5f93a56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "print('{}: {}'.format(device, n_gpu))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkaSEhRSIQqs",
        "colab_type": "code",
        "outputId": "5ad77621-e90d-4508-86fd-0655f5b38271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrQh9wLOfJpC",
        "colab_type": "text"
      },
      "source": [
        "#Load Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EO5x0SxoorZ",
        "colab_type": "text"
      },
      "source": [
        "**Read Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcgSUnfPfIxT",
        "colab_type": "code",
        "outputId": "19974664-e74f-4df8-a79f-fe73d518d60d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/data/ner_product_bio.csv', header=None,\n",
        "                   sep='\\t', encoding='utf8', names=['Sentence#', 'Word', 'Tag'])\n",
        "data.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence#</th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Nhưng</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>hiện_tại</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>bạn</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>đang</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>cho</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>bé</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>bú</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>nên</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>bạn</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>không</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentence#      Word Tag\n",
              "0          1     Nhưng   O\n",
              "1          1  hiện_tại   O\n",
              "2          1       bạn   O\n",
              "3          1      đang   O\n",
              "4          1       cho   O\n",
              "5          1        bé   O\n",
              "6          1        bú   O\n",
              "7          1       nên   O\n",
              "8          1       bạn   O\n",
              "9          1     không   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZZOEJcNioYq",
        "colab_type": "code",
        "outputId": "20739dc6-3e1a-4031-f514-24f93f332533",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "tuple_func = lambda f: [(w, t) for w, t in zip(f['Word'].values, f['Tag'].values)]\n",
        "sentences_with_tag = data.groupby('Sentence#').apply(tuple_func)\n",
        "print(sentences_with_tag)\n",
        "sentences_with_tag = [sent for sent in sentences_with_tag]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence#\n",
            "1       [(Nhưng, O), (hiện_tại, O), (bạn, O), (đang, O...\n",
            "2                        [(Áo, B-pr), (Hm, I-pr), (ạ, O)]\n",
            "3       [(Cho, O), (mình, O), (đặt, O), (cái, O), (bal...\n",
            "4       [(Ac, O), (có, O), (vest, B-pr), (chưa, O), (?...\n",
            "5       [(body, B-pr), (lotion, I-pr), (e, O), (lại, O...\n",
            "                              ...                        \n",
            "2091    [(Dạ, O), (trước, O), (em, O), (có, O), (dùng,...\n",
            "2092    [(_son, B-pr), (black, I-pr), (rouge, I-pr), (...\n",
            "2093    [(da, O), (nươc, I-pr), (hoa, I-pr), (foellie,...\n",
            "2094    [(Hiện, O), (bên, O), (Hương, O), (đang, O), (...\n",
            "2095    [(Kem, B-pr), (dưỡng, I-pr), (ban_đêm, I-pr), ...\n",
            "Length: 2095, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r60imrFdkOpJ",
        "colab_type": "code",
        "outputId": "5dfab983-3117-4714-d7f2-a7b4b710464d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sentences = [' '.join([word[0] for word in sent]) for sent in sentences_with_tag]\n",
        "sentences[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Áo Hm ạ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv4hl9q1kpLq",
        "colab_type": "code",
        "outputId": "7a8fd4eb-4896-4ba6-9ffa-9b01261e87f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "labels = [[word[1] for word in sent] for sent in sentences_with_tag]\n",
        "labels[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-pr', 'I-pr', 'O']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYmGJG8wk_MM",
        "colab_type": "code",
        "outputId": "87b612e9-5b28-44d0-a807-eb8924cbecc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "labels_value = ['B-pr','I-pr','O', 'PAD', '[CLS]', '[SEP]', 'X']\n",
        "label2idx = {label:indx for indx, label in enumerate(labels_value)}\n",
        "label2idx"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-pr': 0, 'I-pr': 1, 'O': 2, 'PAD': 3, 'X': 6, '[CLS]': 4, '[SEP]': 5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq7o6689grKS",
        "colab_type": "text"
      },
      "source": [
        "***Encode with bpe***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRffu0CnmGZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--bpe-codes', \n",
        "    default=\"/content/drive/My Drive/pre_model/phobert/PhoBERT_base_transformers/bpe.codes\",\n",
        "    required=False,\n",
        "    type=str,  \n",
        "    help='path to fastBPE BPE'\n",
        ")\n",
        "args, unknown = parser.parse_known_args()\n",
        "\n",
        "bpe = fastBPE(args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FchxuuOUmgd5",
        "colab_type": "code",
        "outputId": "69921493-f33a-4990-bb68-24a946671a19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "subwords = ['<s> '+bpe.encode(sent)+' </s>' for sent in sentences]\n",
        "subwords[1] "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> Áo H@@ m ạ </s>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ65kPhdnS3k",
        "colab_type": "code",
        "outputId": "f1ffbb0d-d120-4797-daed-f7bd9b50781d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plt.hist([len(s.split()) for s in subwords])\n",
        "plt.xlabel('Number of word')\n",
        "plt.ylabel('Number of sentences')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaS_WRMKoPz9",
        "colab_type": "text"
      },
      "source": [
        "***Change labels by subword***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY3O9SFPn2lQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Đánh label X cho những từ là subword, thêm label [CLS], [SEP] \n",
        "\"\"\"\n",
        "Câu gốc:\n",
        "  Áo Hm ạ --> ['B-pr', 'I-pr', 'O']\n",
        "Câu sau khi encode:\n",
        "  <s> Áo H@@ m ạ </s> --> ['[CLS]', 'B-pr', 'X', 'I-pr', 'O', '[SEP]']\n",
        "\"\"\" \n",
        "label_subwords = []\n",
        "for i in range(len(subwords)):\n",
        "  indx = 0\n",
        "  label = ['[CLS]']\n",
        "  for word in subwords[i].split()[1:MAX_LEN-1]:\n",
        "    if word == '</s>':\n",
        "      break\n",
        "    if '@@' not in word:\n",
        "      label.append(labels[i][indx])\n",
        "      indx += 1\n",
        "      continue\n",
        "    label.append('X')\n",
        "  label.append('[SEP]')\n",
        "  label_subwords.append(label) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJWHuchWyRd6",
        "colab_type": "code",
        "outputId": "d521c3c3-f467-4854-e28a-12b1f9320fa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "label_subwords[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]', 'B-pr', 'X', 'I-pr', 'O', '[SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnoorgFJhvav",
        "colab_type": "text"
      },
      "source": [
        "***String to number***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtM9Wg6kmeMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Dictionary()\n",
        "vocab.add_from_file(\"/content/drive/My Drive/pre_model/phobert/PhoBERT_large_transformers/dict.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj3CxWSknK4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = pad_sequences([vocab.encode_line(sent, append_eos=False, add_if_not_exist=False).long().tolist() for sent in subwords],\n",
        "                          truncating='post', padding='post', maxlen=MAX_LEN, value=1.0, dtype='long')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spjCT1eljz6v",
        "colab_type": "code",
        "outputId": "46d1c3df-9aef-491e-fba3-7e4e99637c4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "input_ids[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0, 3759, 1125,  599, 3628,    2,    1,    1,    1,    1,    1,\n",
              "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "          1,    1,    1,    1,    1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGiwadUIkHLU",
        "colab_type": "code",
        "outputId": "94a1870c-0a0e-454e-ebb9-d6d5e7950198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "labels_ids = pad_sequences([[label2idx.get(label) for label in labels] for labels in label_subwords], dtype='long',\n",
        "                            maxlen=MAX_LEN, value=label2idx['PAD'], truncating='post', padding='post')\n",
        "labels_ids[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 0, 6, 1, 2, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f6nNRWHlNbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attenion_mask = [[float(val != 1) for val in sent] for sent in input_ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5ajISqfmBUF",
        "colab_type": "text"
      },
      "source": [
        "***Create train/validation data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JteRr4K7l6rw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(input_ids, labels_ids, random_state=96, test_size=0.2)\n",
        "train_mask, val_mask, _, _ = train_test_split(attenion_mask, input_ids, random_state=96, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e6zMj1im3Zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change to tensor\n",
        "X_train = torch.tensor(X_train)\n",
        "X_val = torch.tensor(X_val)\n",
        "y_train = torch.tensor(y_train)\n",
        "y_val = torch.tensor(y_val)\n",
        "train_mask = torch.tensor(train_mask)\n",
        "val_mask = torch.tensor(val_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQHBYd-vnTiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create data loader\n",
        "train_data = TensorDataset(X_train, train_mask, y_train)\n",
        "train_sample = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sample, batch_size=batch_sz)\n",
        "\n",
        "val_data = TensorDataset(X_val, val_mask, y_val)\n",
        "val_sample = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sample, batch_size=batch_sz)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9kIr1uRopx_",
        "colab_type": "code",
        "outputId": "4fc9aa8c-dcc7-4c3d-b0c0-6b6946092d4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "val_data[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([    0, 51970,     7,  1164,     8,    17,   534,    54,    32, 12885,\n",
              "            77,   145,   193,    66,   291,   478,    76,   230,     6,   478,\n",
              "           291,  9405,    99,   230,   213,  3628,     5,     2,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]),\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0.]),\n",
              " tensor([4, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "         2, 2, 2, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRTVmBA8ydlO",
        "colab_type": "text"
      },
      "source": [
        "#Feature extractor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqIBBDftqU5c",
        "colab_type": "text"
      },
      "source": [
        "***Load pretrained model PhoBert(base)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8IJ_AzPP3kN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import *\n",
        "from keras.layers import Bidirectional, LSTM, Dense,TimeDistributed, Dropout\n",
        "from keras.models import Model, Input\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "class RobertaForFeatureExtraction(BertPreTrainedModel):\n",
        "   config_class = RobertaConfig\n",
        "   pretrained_model_archive_map = ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP\n",
        "   base_model_prefix = \"roberta\"\n",
        "   def __init__(self, config):\n",
        "       super().__init__(config)\n",
        "       self.roberta = RobertaModel(config)\n",
        "\n",
        "       self.init_weights()\n",
        "\n",
        "   def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None,\n",
        "                start_positions=None, end_positions=None):\n",
        "\n",
        "       outputs = self.roberta(input_ids,\n",
        "                            attention_mask=attention_mask,\n",
        "                            token_type_ids=token_type_ids,\n",
        "                            position_ids=position_ids,\n",
        "                            head_mask=head_mask)\n",
        "       \n",
        "       output = torch.cat((outputs[2][-1],outputs[2][-2], outputs[2][-3], outputs[2][-4]), dim=-1)\n",
        "       return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vFvMGKsqFrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = RobertaConfig.from_pretrained(\n",
        "    \"/content/drive/My Drive/pre_model/phobert/PhoBERT_base_transformers/config.json\",\n",
        "    output_hidden_states=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3NclR75qcj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = RobertaForFeatureExtraction.from_pretrained(\n",
        "    \"/content/drive/My Drive/pre_model/phobert/PhoBERT_base_transformers/model.bin\",\n",
        "    config=config\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nFbgfC3qpRE",
        "colab_type": "code",
        "outputId": "49779332-0a08-4d68-ae34-356e9f917309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# pass model parameter to GPU\n",
        "model.cuda()\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForFeatureExtraction(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLVhe8PHLcGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(dataloader):\n",
        "  datas, labels = [], []\n",
        "  for batch in dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    X, mask, y = batch\n",
        "    with torch.no_grad():\n",
        "      features = model(X, mask)\n",
        "    datas.extend(features.detach().cpu().numpy())\n",
        "    labels.extend(y.to('cpu').numpy())\n",
        "  return datas, labels "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LicSS3vhXkfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = extract_features(train_dataloader)\n",
        "X_val, y_val = extract_features(val_dataloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gehs8H4BlVJz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "y_train = [to_categorical(sent, num_classes=len(label2idx)) for sent in y_train]\n",
        "y_train = np.array(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHZ37iGZzefS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMlEkVv_qP3N",
        "colab_type": "text"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCdwRogMYpRn",
        "colab_type": "code",
        "outputId": "02f0b369-cdc7-4cf0-aa17-dc75f52ec436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "model_in = Input(shape=X_train[0].shape)\n",
        "model_out = LSTM(100, return_sequences=True)(model_in)\n",
        "model_out = Dropout(0.2)(model_out)\n",
        "model_out = Dense(len(label2idx), activation='softmax')(model_out)\n",
        "model = Model(model_in, model_out)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 60, 3072)          0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 60, 100)           1269200   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 60, 100)           0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 60, 7)             707       \n",
            "=================================================================\n",
            "Total params: 1,269,907\n",
            "Trainable params: 1,269,907\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKGguI5MwRQX",
        "colab_type": "text"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRScI0HTk-cx",
        "colab_type": "code",
        "outputId": "86e02275-655a-4f63-d2d1-183710019df2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "model.fit(X_train, y_train, epochs=10, batch_size=16)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1676/1676 [==============================] - 11s 7ms/step - loss: 0.1479\n",
            "Epoch 2/10\n",
            "1676/1676 [==============================] - 11s 7ms/step - loss: 0.0482\n",
            "Epoch 3/10\n",
            "1676/1676 [==============================] - 11s 7ms/step - loss: 0.0360\n",
            "Epoch 4/10\n",
            "1676/1676 [==============================] - 11s 7ms/step - loss: 0.0279\n",
            "Epoch 5/10\n",
            "1676/1676 [==============================] - 11s 7ms/step - loss: 0.0215\n",
            "Epoch 6/10\n",
            "1676/1676 [==============================] - 11s 7ms/step - loss: 0.0165\n",
            "Epoch 7/10\n",
            "1676/1676 [==============================] - 11s 7ms/step - loss: 0.0122\n",
            "Epoch 8/10\n",
            "1676/1676 [==============================] - 11s 7ms/step - loss: 0.0089\n",
            "Epoch 9/10\n",
            "1676/1676 [==============================] - 11s 6ms/step - loss: 0.0065\n",
            "Epoch 10/10\n",
            "1676/1676 [==============================] - 11s 6ms/step - loss: 0.0051\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fe31a5d8e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTQGtV0-dlqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicts =  model.predict(np.array(X_val))\n",
        "predicts = np.argmax(predicts, axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0axPi9dNdeAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Chuyển label đánh theo số về dạng chữ, và bỏ label PAD \n",
        "\n",
        "pred_labels = [labels_value[pred_indx] for pred, true in zip(predicts, y_val)\n",
        "                                      for pred_indx, true_indx in zip(pred, true) if labels_value[true_indx] != 'PAD']\n",
        "true_labels = [labels_value[indx] for true in y_val\n",
        "                                      for indx in true if labels_value[indx] != 'PAD']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yrx-5c5seEPO",
        "colab_type": "code",
        "outputId": "76b4f81b-b248-46f0-94d2-1291bcf1f30a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "f1_score(true_labels, pred_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9102597068655182"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhXBySlHfyJm",
        "colab_type": "text"
      },
      "source": [
        "#Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jhqf6-jGj4LF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_ids_sent = [data[0].numpy() for data in val_data]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmNPQRujf2OZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_subwords = []\n",
        "for sent in val_ids_sent:\n",
        "  val_subwords.extend(('<s> '+ vocab.string(sent) + ' </s>').replace('<pad>', '').split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phk8B67L6rPg",
        "colab_type": "code",
        "outputId": "d8ce3576-fb9a-4dbf-a182-a0278b94fe86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "list(zip(true_labels, pred_labels, val_subwords))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Áo'),\n",
              " ('I-pr', 'I-pr', 'da'),\n",
              " ('X', 'X', 'be@@'),\n",
              " ('X', 'X', 'ver@@'),\n",
              " ('I-pr', 'I-pr', 'ry'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Đặc_thù'),\n",
              " ('O', 'O', 'của'),\n",
              " ('B-pr', 'B-pr', 'tranh'),\n",
              " ('O', 'O', 'là'),\n",
              " ('O', 'O', 'không'),\n",
              " ('O', 'O', 'nặng'),\n",
              " ('O', 'O', 'thì'),\n",
              " ('O', 'O', 'cũng'),\n",
              " ('O', 'O', 'cồng_kềnh'),\n",
              " ('O', 'O', 'nên'),\n",
              " ('O', 'O', 'bên'),\n",
              " ('O', 'O', 'em'),\n",
              " ('O', 'O', 'chỉ'),\n",
              " ('O', 'O', 'hỗ_trợ'),\n",
              " ('O', 'O', 'khách_hàng'),\n",
              " ('O', 'O', '2'),\n",
              " ('O', 'O', 'phần'),\n",
              " ('O', 'O', 'và'),\n",
              " ('O', 'O', 'khách_hàng'),\n",
              " ('O', 'O', 'hỗ_trợ'),\n",
              " ('O', 'O', 'shop'),\n",
              " ('O', 'O', '1'),\n",
              " ('O', 'O', 'phần'),\n",
              " ('O', 'O', 'chị'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('O', 'O', '.'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'O', 'Bộ'),\n",
              " ('I-pr', 'B-pr', 'áo'),\n",
              " ('I-pr', 'I-pr', 'dây'),\n",
              " ('I-pr', 'I-pr', 'quần_đùi'),\n",
              " ('X', 'X', 'b@@'),\n",
              " ('O', 'O', 'n'),\n",
              " ('O', 'O', 'vậy'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('X', 'X', 'Đ@@'),\n",
              " ('B-pr', 'B-pr', 'um'),\n",
              " ('X', 'X', 'red@@'),\n",
              " ('I-pr', 'I-pr', 'leo'),\n",
              " ('O', 'O', '750'),\n",
              " ('X', 'X', 'N@@'),\n",
              " ('O', 'O', 'iềng'),\n",
              " ('X', 'X', '1@@'),\n",
              " ('O', 'O', '150'),\n",
              " ('X', 'X', 'C@@'),\n",
              " ('O', 'O', 'ăm'),\n",
              " ('O', 'O', '250'),\n",
              " ('O', 'O', 'Công'),\n",
              " ('O', 'O', 'bắt'),\n",
              " ('O', 'O', 'căm'),\n",
              " ('O', 'O', '100'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', 'phải'),\n",
              " ('B-pr', 'B-pr', 'laptop'),\n",
              " ('X', 'X', 'd@@'),\n",
              " ('I-pr', 'I-pr', 'ell'),\n",
              " ('O', 'O', 'cũng'),\n",
              " ('O', 'O', 'đc'),\n",
              " ('O', 'O', 'ah'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'M'),\n",
              " ('O', 'O', 'mua'),\n",
              " ('B-pr', 'B-pr', 'sữa'),\n",
              " ('I-pr', 'I-pr', 'rửa'),\n",
              " ('I-pr', 'I-pr', 'mặt'),\n",
              " ('O', 'O', 'cơ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('X', 'X', 'Chà_@@'),\n",
              " ('B-pr', 'B-pr', 'là'),\n",
              " ('O', 'I-pr', 'dẻo'),\n",
              " ('O', 'O', 'nguyên'),\n",
              " ('O', 'O', 'cành'),\n",
              " ('O', 'O', 'nhập_khẩu'),\n",
              " ('O', 'O', 'Israel'),\n",
              " ('O', 'O', '180.000'),\n",
              " ('O', 'O', 'đ'),\n",
              " ('O', 'O', '/'),\n",
              " ('O', 'O', 'hộp'),\n",
              " ('X', 'X', '500@@'),\n",
              " ('O', 'O', 'gr'),\n",
              " ('O', 'O', 'bạn'),\n",
              " ('O', 'O', 'nhé'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'em'),\n",
              " ('O', 'O', 'mua'),\n",
              " ('X', 'X', 's@@'),\n",
              " ('X', 'X', 'r@@'),\n",
              " ('B-pr', 'B-pr', '4'),\n",
              " ('X', 'X', '44@@'),\n",
              " ('I-pr', 'I-pr', 'm'),\n",
              " ('I-pr', 'O', 'đen'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('O', 'O', 'thanh_toán'),\n",
              " ('X', 'X', 'tr@@'),\n",
              " ('O', 'O', 'c'),\n",
              " ('O', 'O', '1m'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'shop'),\n",
              " ('O', 'O', 'có'),\n",
              " ('O', 'O', 'tinh_chất'),\n",
              " ('X', 'X', 'in@@'),\n",
              " ('X', 'X', 'nis@@'),\n",
              " ('B-pr', 'B-pr', 'free'),\n",
              " ('I-pr', 'I-pr', 'lựu'),\n",
              " ('I-pr', 'I-pr', 'đỏ'),\n",
              " ('O', 'O', 'ko'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'B-pr', 'sữa'),\n",
              " ('O', 'I-pr', 'non'),\n",
              " ('O', 'O', 'này'),\n",
              " ('O', 'O', 'bỏ'),\n",
              " ('O', 'O', 'sỉ'),\n",
              " ('O', 'O', 'giá'),\n",
              " ('O', 'O', 'thế_nào'),\n",
              " ('O', 'O', 'vậy'),\n",
              " ('O', 'O', 'chị'),\n",
              " ('O', 'O', 'đẹp'),\n",
              " ('O', 'O', 'ơi'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'dạ'),\n",
              " ('B-pr', 'B-pr', 'kem'),\n",
              " ('I-pr', 'I-pr', 'mắt'),\n",
              " ('X', 'X', 'es@@'),\n",
              " ('I-pr', 'I-pr', 'tee'),\n",
              " ('X', 'X', 'lau@@'),\n",
              " ('I-pr', 'I-pr', 'der'),\n",
              " ('O', 'O', 'bên'),\n",
              " ('O', 'O', 'mình'),\n",
              " ('O', 'O', 'còn'),\n",
              " ('O', 'O', 'mini'),\n",
              " ('O', 'O', 'thôi'),\n",
              " ('O', 'O', 'b'),\n",
              " ('O', 'O', 'nha'),\n",
              " ('O', 'O', '.'),\n",
              " ('X', 'X', '3@@'),\n",
              " ('O', 'O', 'ml'),\n",
              " ('X', 'X', '250@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'sữa'),\n",
              " ('I-pr', 'I-pr', 'sống'),\n",
              " ('O', 'O', 'giá'),\n",
              " ('O', 'O', '2'),\n",
              " ('O', 'O', '8K'),\n",
              " ('O', 'O', '/'),\n",
              " ('O', 'O', '1'),\n",
              " ('X', 'X', 'K@@'),\n",
              " ('O', 'O', 'g'),\n",
              " ('O', 'O', 'từ'),\n",
              " ('X', 'X', '5@@'),\n",
              " ('X', 'X', 'K@@'),\n",
              " ('O', 'O', 'g'),\n",
              " ('O', 'X', 'trở'),\n",
              " ('O', 'O', 'lên'),\n",
              " ('O', 'O', '25'),\n",
              " ('O', 'O', 'K'),\n",
              " ('O', 'O', '/'),\n",
              " ('O', 'O', '1'),\n",
              " ('X', 'X', 'K@@'),\n",
              " ('O', 'O', 'g'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('X', 'X', 'Ari@@'),\n",
              " ('B-pr', 'B-pr', 'pod'),\n",
              " ('O', 'O', 'bên'),\n",
              " ('O', 'O', 'shop'),\n",
              " ('X', 'X', 'new@@'),\n",
              " ('X', 'X', 'se@@'),\n",
              " ('O', 'O', 'al'),\n",
              " ('O', 'O', 'là'),\n",
              " ('O', 'O', 'bao_nhiêu'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Quần'),\n",
              " ('O', 'O', 'này'),\n",
              " ('O', 'O', '46'),\n",
              " ('O', 'O', 'kg'),\n",
              " ('O', 'O', 'mặc'),\n",
              " ('X', 'X', 's@@'),\n",
              " ('O', 'O', 'z'),\n",
              " ('O', 'O', 'j'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Giày'),\n",
              " ('X', 'X', 'y@@'),\n",
              " ('I-pr', 'I-pr', 'z'),\n",
              " ('I-pr', 'O', '700'),\n",
              " ('O', 'O', 'nhiêu'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Dạ'),\n",
              " ('O', 'O', 'bạn'),\n",
              " ('O', 'O', 'tham_khảo'),\n",
              " ('O', 'O', '1'),\n",
              " ('O', 'O', 'số'),\n",
              " ('O', 'O', 'dòng'),\n",
              " ('B-pr', 'B-pr', 'mặt_nạ'),\n",
              " ('O', 'O', 'này'),\n",
              " ('O', 'O', 'ah'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('X', 'X', 'Sof@@'),\n",
              " ('X', 'X', 'a_@@'),\n",
              " ('B-pr', 'B-pr', 'Giường'),\n",
              " ('O', 'O', '2m'),\n",
              " ('O', 'O', 'giá'),\n",
              " ('O', 'O', '5'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'dạ'),\n",
              " ('O', 'O', 'shop'),\n",
              " ('O', 'O', 'không'),\n",
              " ('O', 'O', 'bán'),\n",
              " ('B-pr', 'B-pr', 'móc'),\n",
              " ('I-pr', 'I-pr', 'khoá'),\n",
              " ('I-pr', 'I-pr', 'xe'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Xe'),\n",
              " ('X', 'X', 'And@@'),\n",
              " ('I-pr', 'I-pr', 'er'),\n",
              " ('O', 'O', 'chỉ'),\n",
              " ('O', 'O', 'từ'),\n",
              " ('O', 'O', '690'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', '/'),\n",
              " ('O', 'O', 'chiếc'),\n",
              " ('O', 'O', 'Để'),\n",
              " ('O', 'O', 'hiểu'),\n",
              " ('O', 'O', 'rõ'),\n",
              " ('O', 'O', 'hơn'),\n",
              " ('O', 'O', 'về'),\n",
              " ('O', 'O', 'cộng_đồng'),\n",
              " ('O', 'O', 'xe'),\n",
              " ('O', 'O', 'thăng_bằng'),\n",
              " ('X', 'X', 'AN@@'),\n",
              " ('X', 'X', 'DE@@'),\n",
              " ('B-pr', 'B-pr', 'R'),\n",
              " ('O', 'O', 'và'),\n",
              " ('O', 'O', 'các'),\n",
              " ('O', 'O', 'chương_trình'),\n",
              " ('O', 'O', 'ưu_đãi'),\n",
              " ('O', 'O', 'khuyến_mại'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Dạ'),\n",
              " ('B-pr', 'O', 'bình'),\n",
              " ('X', 'X', 'lan@@'),\n",
              " ('X', 'X', 'si@@'),\n",
              " ('X', 'X', 'o@@'),\n",
              " ('I-pr', 'I-pr', 'h'),\n",
              " ('X', 'X', '220@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'bánh'),\n",
              " ('O', 'O', 'như'),\n",
              " ('O', 'O', 'mẫu'),\n",
              " ('O', 'O', 'là'),\n",
              " ('B-pr', 'B-pr', 'bánh'),\n",
              " ('I-pr', 'I-pr', 'phủ'),\n",
              " ('I-pr', 'I-pr', 'kem'),\n",
              " ('I-pr', 'I-pr', 'sữa'),\n",
              " ('I-pr', 'I-pr', 'bò'),\n",
              " ('I-pr', 'O', 'tươi'),\n",
              " ('I-pr', 'O', 'có'),\n",
              " ('I-pr', 'O', 'cốt'),\n",
              " ('I-pr', 'O', 'bông'),\n",
              " ('I-pr', 'O', 'lan'),\n",
              " ('O', 'O', 'kết_hợp'),\n",
              " ('O', 'O', 'mắc'),\n",
              " ('O', 'O', 'ca'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', '1'),\n",
              " ('O', 'O', 'bộ'),\n",
              " ('X', 'X', 'bar@@'),\n",
              " ('X', 'X', 'celo@@'),\n",
              " ('B-pr', 'B-pr', 'na'),\n",
              " ('O', 'O', 'xanh'),\n",
              " ('O', 'O', 'lý'),\n",
              " ('O', 'O', 'size'),\n",
              " ('O', 'O', 'S'),\n",
              " ('O', 'O', 'Công_Minh'),\n",
              " ('X', 'X', 'sô@@'),\n",
              " ('O', 'O', 'z'),\n",
              " ('O', 'O', '10'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Shop'),\n",
              " ('O', 'O', 'ơi'),\n",
              " ('B-pr', 'B-pr', 'vali'),\n",
              " ('X', 'X', 'nu@@'),\n",
              " ('X', 'X', 'tif@@'),\n",
              " ('I-pr', 'I-pr', 'ood'),\n",
              " ('O', 'O', 'shop'),\n",
              " ('O', 'O', 'còn'),\n",
              " ('O', 'O', 'ko'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Tạm_biệt'),\n",
              " ('O', 'O', 'vết'),\n",
              " ('O', 'O', 'thâm'),\n",
              " ('O', 'I-pr', 'nám'),\n",
              " ('O', 'O', 'với'),\n",
              " ('O', 'O', 'sản_phẩm'),\n",
              " ('X', 'X', 'Tinh_@@'),\n",
              " ('O', 'O', 'chất'),\n",
              " ('O', 'O', 'điều_trị'),\n",
              " ('O', 'O', 'độc_đáo'),\n",
              " ('O', 'O', 'của'),\n",
              " ('X', 'X', 'Paul@@'),\n",
              " ('O', 'O', 'a'),\n",
              " ('O', 'O', 's'),\n",
              " ('X', 'X', 'Cho@@'),\n",
              " ('O', 'O', 'ice'),\n",
              " ('O', 'O', 'với'),\n",
              " ('O', 'O', 'thành_phần'),\n",
              " ('O', 'O', 'hiệu_quả'),\n",
              " ('O', 'O', '1'),\n",
              " ('X', 'X', 'Ret@@'),\n",
              " ('X', 'X', 'in@@'),\n",
              " ('B-pr', 'O', 'ol'),\n",
              " ('O', 'O', '.'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'mình'),\n",
              " ('O', 'O', 'lấy'),\n",
              " ('O', 'O', 'cả'),\n",
              " ('O', 'O', 'bộ'),\n",
              " ('O', 'B-pr', 'đan'),\n",
              " ('O', 'I-pr', 'tay'),\n",
              " ('O', 'I-pr', 'nâu'),\n",
              " ('X', 'X', 'be@@'),\n",
              " ('B-pr', 'I-pr', 'ige'),\n",
              " ('O', 'O', 'chị'),\n",
              " ('O', 'O', 'ha'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('X', 'X', 'hi@@'),\n",
              " ('O', 'O', 'en'),\n",
              " ('O', 'O', 'e'),\n",
              " ('O', 'O', 'đang'),\n",
              " ('O', 'O', 'còn'),\n",
              " ('B-pr', 'O', 'quần'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'dạ'),\n",
              " ('X', 'X', '100@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('B-pr', 'O', 'ốp'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Bộ'),\n",
              " ('B-pr', 'B-pr', 'sofa'),\n",
              " ('I-pr', 'I-pr', '4'),\n",
              " ('I-pr', 'I-pr', 'ngăn_kéo'),\n",
              " ('O', 'O', 'này'),\n",
              " ('O', 'O', 'kích_thước'),\n",
              " ('O', 'O', '1m70'),\n",
              " ('O', 'O', 'x'),\n",
              " ('X', 'X', '2@@'),\n",
              " ('X', 'X', 'm@@'),\n",
              " ('O', 'O', '75'),\n",
              " ('O', 'O', 'bên'),\n",
              " ('O', 'O', 'em'),\n",
              " ('O', 'O', 'đang'),\n",
              " ('O', 'O', 'bán'),\n",
              " ('O', 'O', 'là'),\n",
              " ('X', 'X', '18.@@'),\n",
              " ('O', 'O', '400.000'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('O', 'O', '.'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'dạ'),\n",
              " ('O', 'O', 'còn'),\n",
              " ('B-pr', 'B-pr', 'set'),\n",
              " ('X', 'X', 'w@@'),\n",
              " ('I-pr', 'B-pr', 'ild'),\n",
              " ('I-pr', 'I-pr', 'cat'),\n",
              " ('O', 'O', 'có'),\n",
              " ('O', 'O', 'giá'),\n",
              " ('O', 'O', 'đang'),\n",
              " ('O', 'O', 'sale'),\n",
              " ('O', 'O', 'là'),\n",
              " ('X', 'X', '24@@'),\n",
              " ('X', 'X', '5@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', 'đó'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Sữa'),\n",
              " ('I-pr', 'I-pr', 'rửa'),\n",
              " ('I-pr', 'I-pr', 'mặt'),\n",
              " ('O', 'O', 'hết'),\n",
              " ('O', 'O', 'rồi'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Giày'),\n",
              " ('O', 'O', 'đó'),\n",
              " ('O', 'O', 'e'),\n",
              " ('O', 'O', 'ko'),\n",
              " ('O', 'O', 'có'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Đầm'),\n",
              " ('I-pr', 'I-pr', 'thun'),\n",
              " ('I-pr', 'I-pr', 'hoa'),\n",
              " ('O', 'O', 'dáng'),\n",
              " ('O', 'O', 'dài'),\n",
              " ('O', 'O', 'giá'),\n",
              " ('X', 'X', '5@@'),\n",
              " ('X', 'X', '60@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', 'chị'),\n",
              " ('O', 'O', 'nha'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Ghế'),\n",
              " ('I-pr', 'I-pr', 'gỗ'),\n",
              " ('I-pr', 'I-pr', 'thông'),\n",
              " ('O', 'O', '.'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Hôm_nay'),\n",
              " ('X', 'X', 'ng@@'),\n",
              " ('O', 'O', 'ta'),\n",
              " ('O', 'O', 'hẹn'),\n",
              " ('O', 'O', 'giao'),\n",
              " ('B-pr', 'B-pr', 'quần'),\n",
              " ('I-pr', 'O', 'xanh'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', '2'),\n",
              " ('X', 'X', 'mắm_t@@'),\n",
              " ('B-pr', 'B-pr', 'ép'),\n",
              " ('O', 'O', '1'),\n",
              " ('B-pr', 'O', 'gà'),\n",
              " ('O', 'O', 'Em'),\n",
              " ('O', 'O', 'nhé'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('X', 'X', 'ni@@'),\n",
              " ('B-pr', 'B-pr', 'ke'),\n",
              " ('O', 'O', 'luôn'),\n",
              " ('O', 'O', 'đúng'),\n",
              " ('O', 'O', 'ko'),\n",
              " ('O', 'O', 'b'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('X', 'X', 'v@@'),\n",
              " ('X', 'X', '5@@'),\n",
              " ('X', 'X', '15@@'),\n",
              " ('B-pr', 'B-pr', 'b'),\n",
              " ('X', 'X', '150@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Accent'),\n",
              " ('I-pr', 'I-pr', '18'),\n",
              " ('O', 'O', 'có'),\n",
              " ('O', 'O', 'sẵn'),\n",
              " ('O', 'O', 'bản'),\n",
              " ('O', 'O', 'chuẩn'),\n",
              " ('O', 'O', 'theo'),\n",
              " ('O', 'O', 'xe'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Đầm'),\n",
              " ('I-pr', 'I-pr', 'thun'),\n",
              " ('I-pr', 'I-pr', 'hoa'),\n",
              " ('I-pr', 'O', 'dáng'),\n",
              " ('I-pr', 'O', 'dài'),\n",
              " ('O', 'O', 'giá'),\n",
              " ('X', 'X', '5@@'),\n",
              " ('X', 'X', '60@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', 'chị'),\n",
              " ('O', 'O', 'nha'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Hiện'),\n",
              " ('O', 'O', 'bên'),\n",
              " ('O', 'O', 'em'),\n",
              " ('O', 'O', 'có'),\n",
              " ('O', 'O', 'dòng'),\n",
              " ('B-pr', 'B-pr', 'áo'),\n",
              " ('I-pr', 'I-pr', 'trắng'),\n",
              " ('I-pr', 'I-pr', 'Oxford'),\n",
              " ('O', 'I-pr', '100'),\n",
              " ('O', 'I-pr', 'cotton'),\n",
              " ('O', 'O', 'dày_dặn'),\n",
              " ('O', 'O', 'thấm'),\n",
              " ('O', 'O', 'mồ_hôi'),\n",
              " ('O', 'O', 'rất'),\n",
              " ('O', 'O', 'tốt'),\n",
              " ('O', 'O', 'anh'),\n",
              " ('O', 'O', 'nhé'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'áo_khoác'),\n",
              " ('O', 'O', 'đó'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('X', 'X', 'Ho@@'),\n",
              " ('X', 'X', 'a_t@@'),\n",
              " ('B-pr', 'B-pr', 'ai'),\n",
              " ('X', 'X', 'Quảng_@@'),\n",
              " ('X', 'X', 'Châu_@@'),\n",
              " ('I-pr', 'I-pr', 'Thái_Lan'),\n",
              " ('O', 'O', 'cao_cấp'),\n",
              " ('O', 'O', '.'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Chào'),\n",
              " ('O', 'O', 'bạn'),\n",
              " ('B-pr', 'B-pr', 'Kẹo'),\n",
              " ('O', 'O', 'bổ_sung'),\n",
              " ('X', 'X', 'd@@'),\n",
              " ('B-pr', 'O', 'ha'),\n",
              " ('O', 'O', 'cho'),\n",
              " ('O', 'O', 'bé'),\n",
              " ('O', 'O', 'giá'),\n",
              " ('X', 'X', '350@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', 'bạn'),\n",
              " ('O', 'O', 'nha'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Các'),\n",
              " ('O', 'O', 'dòng'),\n",
              " ('X', 'X', 'Kal@@'),\n",
              " ('X', 'X', 'im@@'),\n",
              " ('B-pr', 'B-pr', 'ba'),\n",
              " ('O', 'O', 'sẽ'),\n",
              " ('O', 'O', 'có'),\n",
              " ('O', 'O', 'âm_thanh'),\n",
              " ('O', 'O', 'khác'),\n",
              " ('O', 'O', 'nhau'),\n",
              " ('O', 'O', 'một_chút'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Hiện_tại'),\n",
              " ('O', 'O', 'shop'),\n",
              " ('O', 'O', 'có'),\n",
              " ('O', 'O', 'những'),\n",
              " ('O', 'O', 'dòng'),\n",
              " ('B-pr', 'B-pr', 'rùa'),\n",
              " ('O', 'O', 'sau'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'dạ'),\n",
              " ('B-pr', 'B-pr', 'gạo'),\n",
              " ('I-pr', 'I-pr', 'lứt'),\n",
              " ('I-pr', 'I-pr', 'dẻo'),\n",
              " ('O', 'O', 'là'),\n",
              " ('O', 'O', '35'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', '/'),\n",
              " ('O', 'O', 'kg'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Rồi'),\n",
              " ('O', 'O', 'thoa'),\n",
              " ('B-pr', 'B-pr', 'thuốc'),\n",
              " ('I-pr', 'I-pr', 'tái_tạo'),\n",
              " ('I-pr', 'I-pr', 'da'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('X', 'X', 'i@@'),\n",
              " ('X', 'X', 'P@@'),\n",
              " ('B-pr', 'B-pr', '7'),\n",
              " ('X', 'X', '32@@'),\n",
              " ('I-pr', 'O', 'G'),\n",
              " ('O', 'O', 'Trắng'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Dạ'),\n",
              " ('O', 'O', 'bạn'),\n",
              " ('O', 'O', 'có_thể'),\n",
              " ('O', 'O', 'tham_khảo'),\n",
              " ('X', 'X', 'cus@@'),\n",
              " ('X', 'X', 'hi@@'),\n",
              " ('B-pr', 'B-pr', 'on'),\n",
              " ('X', 'X', 'Cli@@'),\n",
              " ('I-pr', 'I-pr', 'o'),\n",
              " ('O', 'O', 'nhé'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('O', 'O', '3'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'cảm_ơn'),\n",
              " ('O', 'O', 'em'),\n",
              " ('B-pr', 'B-pr', 'Cốt'),\n",
              " ('I-pr', 'I-pr', 'yến'),\n",
              " ('O', 'O', 'này'),\n",
              " ('O', 'O', 'là'),\n",
              " ('O', 'O', 'dòng'),\n",
              " ('O', 'O', 'cao_cấp'),\n",
              " ('O', 'O', 'trắng'),\n",
              " ('O', 'O', 'nhanh'),\n",
              " ('X', 'X', 'p@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', 'c'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('X', 'X', 'En@@'),\n",
              " ('B-pr', 'B-pr', 'vy'),\n",
              " ('I-pr', 'O', 'size'),\n",
              " ('X', 'X', 'n@@'),\n",
              " ('X', 'X', 't@@'),\n",
              " ('O', 'O', 'n'),\n",
              " ('O', 'O', 'em'),\n",
              " ('O', 'O', '?'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Đầm'),\n",
              " ('O', 'I-pr', 'giá'),\n",
              " ('O', 'I-pr', 'sao'),\n",
              " ('O', 'O', 'shop'),\n",
              " ('O', 'O', '.'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Dạ'),\n",
              " ('O', 'O', 'mẫu'),\n",
              " ('B-pr', 'B-pr', 'đầm'),\n",
              " ('I-pr', 'I-pr', 'trắng'),\n",
              " ('I-pr', 'O', '2'),\n",
              " ('I-pr', 'O', 'lớp'),\n",
              " ('O', 'O', 'bạn'),\n",
              " ('O', 'O', 'nhé'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Mẫu'),\n",
              " ('X', 'X', 'M@@'),\n",
              " ('X', 'X', '4@@'),\n",
              " ('B-pr', 'O', '700'),\n",
              " ('O', 'O', 'màn'),\n",
              " ('O', 'O', '15.6'),\n",
              " ('O', 'O', 'ram'),\n",
              " ('X', 'X', '8@@'),\n",
              " ('X', 'X', 'g@@'),\n",
              " ('O', 'O', 'b'),\n",
              " ('O', 'O', 'chíp'),\n",
              " ('O', 'O', 'i7'),\n",
              " ('O', 'O', 'ổ'),\n",
              " ('X', 'X', 'ss@@'),\n",
              " ('O', 'O', 'd'),\n",
              " ('O', 'O', '256'),\n",
              " ('O', 'O', '.'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Mũ'),\n",
              " ('I-pr', 'X', 'full'),\n",
              " ('I-pr', 'I-pr', 'face'),\n",
              " ('O', 'O', 'mà'),\n",
              " ('O', 'O', 'màu'),\n",
              " ('O', 'O', 'đen'),\n",
              " ('O', 'O', 'ấy'),\n",
              " ('O', 'O', 'bạn'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Tại'),\n",
              " ('X', 'X', 'thi@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('B-pr', 'B-pr', 'khăn'),\n",
              " ('X', 'X', 'di@@'),\n",
              " ('I-pr', 'I-pr', 'or'),\n",
              " ('I-pr', 'O', 'trắng'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Bánh'),\n",
              " ('O', 'O', 'có'),\n",
              " ('O', 'O', 'sẵn'),\n",
              " ('O', 'O', 'ha'),\n",
              " ('O', 'O', 'b'),\n",
              " ('O', 'O', '?'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', '11'),\n",
              " ('I-pr', 'I-pr', '64GB'),\n",
              " ('X', 'X', 'White_@@'),\n",
              " ('X', 'X', 'Full@@'),\n",
              " ('I-pr', 'I-pr', 'box'),\n",
              " ('O', 'O', '25'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'khăn'),\n",
              " ('I-pr', 'I-pr', 'vải'),\n",
              " ('I-pr', 'I-pr', 'khô'),\n",
              " ('I-pr', 'O', 'đa_năng'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'C'),\n",
              " ('O', 'O', 'bảo'),\n",
              " ('B-pr', 'B-pr', 'kem'),\n",
              " ('I-pr', 'I-pr', 'chống'),\n",
              " ('I-pr', 'I-pr', 'nắng'),\n",
              " ('O', 'O', 'c'),\n",
              " ('O', 'O', 'báo'),\n",
              " ('O', 'O', 'nhầm'),\n",
              " ('O', 'O', 'giá'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Chai'),\n",
              " ('I-pr', 'I-pr', 'xịt'),\n",
              " ('O', 'O', 'bảo_vệ'),\n",
              " ('O', 'O', 'bé'),\n",
              " ('O', 'O', 'chống'),\n",
              " ('O', 'O', 'lây_nhiễm'),\n",
              " ('O', 'O', 'các'),\n",
              " ('O', 'O', 'vi_khuẩn'),\n",
              " ('O', 'O', 'lây'),\n",
              " ('O', 'O', 'bệnh'),\n",
              " ('O', 'O', 'như'),\n",
              " ('O', 'O', 'chân_tay'),\n",
              " ('O', 'B-pr', 'miệng'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Dạ'),\n",
              " ('O', 'O', 'tớ'),\n",
              " ('X', 'X', 'cò@@'),\n",
              " ('X', 'X', 'n_s@@'),\n",
              " ('O', 'O', 'on'),\n",
              " ('B-pr', 'O', 'thỏi'),\n",
              " ('X', 'X', 'N@@'),\n",
              " ('I-pr', 'I-pr', '5'),\n",
              " ('I-pr', 'O', 'màu'),\n",
              " ('I-pr', 'O', 'đỏ'),\n",
              " ('I-pr', 'O', 'cam'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Cho'),\n",
              " ('O', 'O', 'mình'),\n",
              " ('X', 'X', 'ho@@'),\n",
              " ('O', 'B-pr', 'it'),\n",
              " ('O', 'I-pr', 'tôm_hùm'),\n",
              " ('B-pr', 'I-pr', 'tre'),\n",
              " ('X', 'X', 'b@@'),\n",
              " ('O', 'O', 'n'),\n",
              " ('O', 'O', ','),\n",
              " ('O', 'O', '1kg'),\n",
              " ('O', 'O', 'đ'),\n",
              " ('O', 'O', 'mấy'),\n",
              " ('O', 'O', 'con'),\n",
              " ('O', 'O', 'vậy'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Bao_nhiêu'),\n",
              " ('O', 'O', 'ml'),\n",
              " ('O', 'O', 'vậy'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('O', 'B-pr', 'Sữa'),\n",
              " ('O', 'I-pr', 'non'),\n",
              " ('O', 'O', 'bao_nhiêu'),\n",
              " ('O', 'O', 'dạ'),\n",
              " ('O', 'O', 'c'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'cái'),\n",
              " ('B-pr', 'B-pr', 'xe_đạp'),\n",
              " ('X', 'X', 'X@@'),\n",
              " ('I-pr', 'I-pr', 'aming'),\n",
              " ('O', 'O', 'ở'),\n",
              " ('O', 'O', 'cửa_hàng'),\n",
              " ('O', 'O', 'mình'),\n",
              " ('O', 'O', 'có'),\n",
              " ('B-pr', 'O', 'xe'),\n",
              " ('I-pr', 'O', 'ráp'),\n",
              " ('I-pr', 'O', 'sẵn'),\n",
              " ('O', 'O', 'ko'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Dạ'),\n",
              " ('B-pr', 'O', 'bưởi'),\n",
              " ('O', 'O', 'e'),\n",
              " ('O', 'O', 'có'),\n",
              " ('B-pr', 'B-pr', 'bưởi'),\n",
              " ('I-pr', 'I-pr', 'da'),\n",
              " ('I-pr', 'I-pr', 'xanh'),\n",
              " ('O', 'O', 'đặc'),\n",
              " ('O', 'O', 'biêt'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Bên'),\n",
              " ('O', 'O', 'em'),\n",
              " ('O', 'O', 'về'),\n",
              " ('O', 'O', 'chỉ'),\n",
              " ('O', 'O', '100'),\n",
              " ('B-pr', 'B-pr', 'quần'),\n",
              " ('X', 'X', 'DUY@@'),\n",
              " ('X', 'X', '_@@'),\n",
              " ('O', 'O', 'NHẤT'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'dạ'),\n",
              " ('O', 'O', 'đúng'),\n",
              " ('O', 'O', 'rồi'),\n",
              " ('O', 'O', '..'),\n",
              " ('B-pr', 'B-pr', 'táo'),\n",
              " ('O', 'O', 'để'),\n",
              " ('O', 'O', 'mỗi'),\n",
              " ('O', 'O', 'hộp'),\n",
              " ('O', 'O', '1kg'),\n",
              " ('O', 'O', 'nha'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Váy'),\n",
              " ('I-pr', 'I-pr', 'dập'),\n",
              " ('I-pr', 'I-pr', 'ly'),\n",
              " ('X', 'X', 'phối_@@'),\n",
              " ('I-pr', 'I-pr', 'ren'),\n",
              " ('I-pr', 'O', 'vai'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Shop'),\n",
              " ('O', 'O', 'có'),\n",
              " ('O', 'O', 'dáng'),\n",
              " ('X', 'X', 'bag@@'),\n",
              " ('B-pr', 'B-pr', 'gy'),\n",
              " ('O', 'O', 'và'),\n",
              " ('B-pr', 'B-pr', 'skinny'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Office'),\n",
              " ('I-pr', 'O', 'bản_quyền'),\n",
              " ('O', 'O', 'vĩnh_viễn'),\n",
              " ('O', 'B-pr', 'Túi'),\n",
              " ('O', 'I-pr', 'chống'),\n",
              " ('O', 'I-pr', 'sốc'),\n",
              " ('O', 'O', 'cao_cấp'),\n",
              " ('O', 'O', 'trị_giá'),\n",
              " ('X', 'X', '350@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('B-pr', 'O', 'Chuột'),\n",
              " ('X', 'X', 'logi@@'),\n",
              " ('I-pr', 'B-pr', 'tech'),\n",
              " ('I-pr', 'O', 'k'),\n",
              " ('I-pr', 'O', 'dây'),\n",
              " ('O', 'O', 'trị_giá'),\n",
              " ('X', 'X', '300@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Giá'),\n",
              " ('B-pr', 'B-pr', 'hoa'),\n",
              " ('O', 'O', 'thế_nào'),\n",
              " ('O', 'O', 'b'),\n",
              " ('O', 'O', '?'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Hơn'),\n",
              " ('O', 'O', 'trước'),\n",
              " ('O', 'O', 'mình'),\n",
              " ('O', 'O', 'có'),\n",
              " ('O', 'O', 'hỏi'),\n",
              " ('O', 'B-pr', 'bộ'),\n",
              " ('B-pr', 'I-pr', 'sạc'),\n",
              " ('I-pr', 'I-pr', 'tay'),\n",
              " ('I-pr', 'I-pr', 'nghe'),\n",
              " ('X', 'X', 'i@@'),\n",
              " ('I-pr', 'O', '4'),\n",
              " ('O', 'O', 'ah'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', '1'),\n",
              " ('B-pr', 'O', 'thùng'),\n",
              " ('X', 'X', 'c@@'),\n",
              " ('I-pr', 'B-pr', '4'),\n",
              " ('O', 'O', 'đen'),\n",
              " ('O', 'O', 'lon'),\n",
              " ('O', 'O', ')'),\n",
              " ('O', 'O', ')'),\n",
              " ('O', 'O', ')'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Dạ'),\n",
              " ('O', 'O', 'set'),\n",
              " ('B-pr', 'B-pr', 'váy_áo'),\n",
              " ('I-pr', 'I-pr', 'khoác'),\n",
              " ('I-pr', 'I-pr', 'kaki'),\n",
              " ('X', 'X', '28@@'),\n",
              " ('X', 'X', '5@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Ôi'),\n",
              " ('B-pr', 'B-pr', 'mũ'),\n",
              " ('X', 'X', 'hê@@'),\n",
              " ('O', 'I-pr', 't'),\n",
              " ('O', 'O', 'r'),\n",
              " ('X', 'X', 'ạ@@'),\n",
              " ('O', 'O', 'h'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'dạ'),\n",
              " ('O', 'O', '4'),\n",
              " ('O', 'O', 'bộ'),\n",
              " ('O', 'O', 'bé'),\n",
              " ('X', 'X', '70@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', '3'),\n",
              " ('X', 'X', '2@@'),\n",
              " ('X', 'X', '10@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', '1'),\n",
              " ('O', 'O', 'bộ'),\n",
              " ('O', 'O', 'mẹ'),\n",
              " ('X', 'X', '160@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', '1'),\n",
              " ('O', 'O', 'bộ'),\n",
              " ('X', 'X', 'm@@'),\n",
              " ('B-pr', 'B-pr', 'icky'),\n",
              " ('X', 'X', '80@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('X', 'X', 'Shi@@'),\n",
              " ('O', 'O', 'p'),\n",
              " ('X', 'X', '30@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('X', 'X', '480@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', 'a'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'O', 'túi'),\n",
              " ('O', 'O', 'hết'),\n",
              " ('O', 'O', 'rồi'),\n",
              " ('O', 'O', 'ah'),\n",
              " ('O', 'O', 'b'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'E'),\n",
              " ('O', 'O', 'muốn'),\n",
              " ('O', 'O', 'mua'),\n",
              " ('X', 'X', 's@@'),\n",
              " ('X', 'X', 'r@@'),\n",
              " ('B-pr', 'B-pr', 'm'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Áo_khoác'),\n",
              " ('I-pr', 'I-pr', 'kaki'),\n",
              " ('O', 'O', 'giá'),\n",
              " ('O', 'O', '170'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', '/'),\n",
              " ('O', 'O', '1'),\n",
              " ('O', 'O', 'cái'),\n",
              " ('O', 'O', 'r'),\n",
              " ('O', 'O', '300'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', '/'),\n",
              " ('O', 'O', '2'),\n",
              " ('O', 'O', 'cái'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'N'),\n",
              " ('X', 'X', '75@@'),\n",
              " ('O', 'O', 'kg'),\n",
              " ('O', 'O', 'mặc'),\n",
              " ('B-pr', 'B-pr', 'áo'),\n",
              " ('I-pr', 'I-pr', 'kaki'),\n",
              " ('O', 'O', 'có'),\n",
              " ('O', 'O', 'rộng'),\n",
              " ('O', 'O', 'k'),\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk60B5uRZLw6",
        "colab_type": "text"
      },
      "source": [
        "#Save & load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymwxGm4rbtE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = '/content/drive/My Drive/pre_model/phobert/ner_product/model_base_state_dict.pt'\n",
        "labels_value = ['B-pr', 'I-pr', 'O', 'X', '[CLS]', '[SEP]', 'PAD']\n",
        "label2idx = {label:indx for indx, label in enumerate(labels_value)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqOOUeNnwtGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(),PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAHX6188hDeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import *\n",
        "\n",
        "class Ner(BertPreTrainedModel):\n",
        "    config_class = RobertaConfig\n",
        "    pretrained_model_archive_map = ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP\n",
        "    base_model_prefix = \"roberta\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "\n",
        "        self.roberta = RobertaModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "    ):\n",
        "\n",
        "        outputs = self.roberta(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "        )\n",
        "\n",
        "        sequence_output = outputs[0]\n",
        "\n",
        "        sequence_output = self.dropout(sequence_output)\n",
        "        logits = self.classifier(sequence_output)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_sba7lRcv66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = RobertaConfig.from_pretrained(\n",
        "    \"/content/drive/My Drive/pre_model/phobert/PhoBERT_base_transformers/config.json\",\n",
        "    num_labels=len(label2idx)\n",
        ")\n",
        "\n",
        "ner = Ner.from_pretrained(\n",
        "    \"/content/drive/My Drive/pre_model/phobert/PhoBERT_base_transformers/model.bin\",\n",
        "    config=config\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjblyC4Lbj67",
        "colab_type": "code",
        "outputId": "972d07cd-6cbb-40d4-bc78-d04659080b02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "ner.load_state_dict(torch.load(PATH))\n",
        "ner.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ner(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2HOIe277Vly",
        "colab_type": "text"
      },
      "source": [
        "#Test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOq-cl3zC817",
        "colab_type": "text"
      },
      "source": [
        "***Must use VnCoreNLP to tokenize before test***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Sf-gL-L7aKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sentence = 'Cho mình hỏi giữa redmi note 9s và samsung glx A31 thì tốc_độ xử_lí và pin ( thực_tế) loại nào tốt hơn vậy.'\n",
        "sent = '<s> ' + bpe.encode(test_sentence) +' </s>'\n",
        "sent_ids = vocab.encode_line(sent, append_eos=False, add_if_not_exist=False).long().tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6LCBRPK7fLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_sentence = pad_sequences([sent_ids], maxlen=MAX_LEN, dtype=\"long\", value=1.0, truncating=\"post\", padding=\"post\")\n",
        "input_ids = torch.tensor(tokenized_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMRn5tZd7z31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask = [[float(m != 1) for m in val] for val in input_ids]\n",
        "mask = torch.tensor(mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwc5Ji7m727W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    output = ner(input_ids, mask)\n",
        "label_ids = np.argmax(output[0].numpy(), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0-Qw0BdYfAT",
        "colab_type": "code",
        "outputId": "fdabe499-bdab-497f-a523-5950a5b678b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "source": [
        "subword_label = list(zip([labels_value[label] for label in label_ids], sent.split()))\n",
        "subword_label"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('[CLS]', '<s>'),\n",
              " ('O', 'Cho'),\n",
              " ('O', 'mình'),\n",
              " ('O', 'hỏi'),\n",
              " ('O', 'giữa'),\n",
              " ('PAD', 'red@@'),\n",
              " ('B-pr', 'mi'),\n",
              " ('I-pr', 'note'),\n",
              " ('PAD', '9@@'),\n",
              " ('I-pr', 's'),\n",
              " ('O', 'và'),\n",
              " ('PAD', 'sam@@'),\n",
              " ('B-pr', 'sung'),\n",
              " ('PAD', 'g@@'),\n",
              " ('PAD', 'l@@'),\n",
              " ('I-pr', 'x'),\n",
              " ('PAD', 'A@@'),\n",
              " ('I-pr', '31'),\n",
              " ('O', 'thì'),\n",
              " ('O', 'tốc_độ'),\n",
              " ('O', 'xử_lí'),\n",
              " ('O', 'và'),\n",
              " ('O', 'pin'),\n",
              " ('O', '('),\n",
              " ('PAD', 'thực_t@@'),\n",
              " ('O', 'ế@@'),\n",
              " ('O', ')'),\n",
              " ('O', 'loại'),\n",
              " ('O', 'nào'),\n",
              " ('O', 'tốt'),\n",
              " ('O', 'hơn'),\n",
              " ('PAD', 'vậ@@'),\n",
              " ('O', 'y.'),\n",
              " ('[SEP]', '</s>')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx2d8MTsYz7c",
        "colab_type": "code",
        "outputId": "e8e1771f-0de2-455e-8295-18b2be6a5073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "sentence = []\n",
        "labels = []\n",
        "word = ''\n",
        "for label, sword in subword_label:\n",
        "  if '@@' not in sword:\n",
        "    word += sword\n",
        "    sentence.append(word)\n",
        "    labels.append(label)\n",
        "    word = ''\n",
        "    continue\n",
        "  word += sword.replace('@@', '')\n",
        "\n",
        "list(zip(sentence, labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<s>', '[CLS]'),\n",
              " ('Cho', 'O'),\n",
              " ('mình', 'O'),\n",
              " ('hỏi', 'O'),\n",
              " ('giữa', 'O'),\n",
              " ('redmi', 'B-pr'),\n",
              " ('note', 'I-pr'),\n",
              " ('9s', 'I-pr'),\n",
              " ('và', 'O'),\n",
              " ('samsung', 'B-pr'),\n",
              " ('glx', 'I-pr'),\n",
              " ('A31', 'I-pr'),\n",
              " ('thì', 'O'),\n",
              " ('tốc_độ', 'O'),\n",
              " ('xử_lí', 'O'),\n",
              " ('và', 'O'),\n",
              " ('pin', 'O'),\n",
              " ('(', 'O'),\n",
              " ('thực_tế)', 'O'),\n",
              " ('loại', 'O'),\n",
              " ('nào', 'O'),\n",
              " ('tốt', 'O'),\n",
              " ('hơn', 'O'),\n",
              " ('vậy.', 'O'),\n",
              " ('</s>', '[SEP]')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1AuVZ-ymK3f",
        "colab_type": "code",
        "outputId": "a3e750df-d8ea-4d27-db49-3fb53d446dbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Product perform by upper word\n",
        "sentence2string = ''\n",
        "for word, label in list(zip(sentence, labels))[1:len(sentence)-1]:\n",
        "  if label == 'O':\n",
        "    sentence2string += (word.lower() +' ')\n",
        "    continue\n",
        "  sentence2string += (word.upper() +' ')\n",
        "sentence2string"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cho mình hỏi giữa REDMI NOTE 9S và SAMSUNG GLX A31 thì tốc_độ xử_lí và pin ( thực_tế) loại nào tốt hơn vậy. '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX6aTV7fK_lr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}