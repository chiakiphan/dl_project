{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_Product(PhoBert_base).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hqFZ9S8iYjAt",
        "DrQh9wLOfJpC",
        "jMlEkVv_qP3N",
        "iKGguI5MwRQX",
        "hhXBySlHfyJm",
        "rk60B5uRZLw6",
        "C2HOIe277Vly"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1c5ee89a77ed425180a1fc11c12c4c4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e5f2bbd51ba7487dbb4b2f2c6ece4635",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9a5cf02acb084c919feb9a186b205dc4",
              "IPY_MODEL_c2eb890c8028485d8a96cc9f8a5d504c"
            ]
          }
        },
        "e5f2bbd51ba7487dbb4b2f2c6ece4635": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a5cf02acb084c919feb9a186b205dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d8205c9452f74b1d80abc3859941cb31",
            "_dom_classes": [],
            "description": "Epoch: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_201b144a67a743d09a8cb0d7ca641998"
          }
        },
        "c2eb890c8028485d8a96cc9f8a5d504c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9fdaa26b78a14ad08e90eb664281bca3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [03:05&lt;00:00, 37.14s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e4f71ede9622408c8ad7ae8d55e3c71a"
          }
        },
        "d8205c9452f74b1d80abc3859941cb31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "201b144a67a743d09a8cb0d7ca641998": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9fdaa26b78a14ad08e90eb664281bca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e4f71ede9622408c8ad7ae8d55e3c71a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqFZ9S8iYjAt",
        "colab_type": "text"
      },
      "source": [
        "#Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTpTqgffYdFj",
        "colab_type": "code",
        "outputId": "063a3c7c-f5b2-4362-c5d9-07437875292e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        }
      },
      "source": [
        "!pip install transformers==2.6.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/a0/32e3a4501ef480f7ea01aac329a716132f32f7911ef1c2fac228acc57ca7/transformers-2.6.0-py3-none-any.whl (540kB)\n",
            "\r\u001b[K     |▋                               | 10kB 29.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |██▍                             | 40kB 2.0MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 2.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 61kB 2.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |████▉                           | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 92kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 102kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 112kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 122kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 133kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 143kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 153kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 163kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 174kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 184kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 194kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 204kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 215kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 225kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 235kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 245kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 256kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 266kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 276kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 286kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 296kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 307kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 317kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 327kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 337kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 348kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 358kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 368kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 378kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 389kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 399kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 409kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 419kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 430kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 440kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 450kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 460kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 471kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 481kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 491kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 501kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 512kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 522kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 532kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 542kB 3.3MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/88/49e772d686088e1278766ad68a463513642a2a877487decbd691dec02955/sentencepiece-0.1.90-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 31.8MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 36.9MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 43.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 27.5MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 21.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 61kB 23.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 20.7MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 22.3MB/s eta 0:00:01\r\u001b[K     |██▊                             | 92kB 21.1MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 19.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 112kB 19.2MB/s eta 0:00:01\r\u001b[K     |███▊                            | 122kB 19.2MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 19.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 143kB 19.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 153kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 174kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 184kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 194kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 204kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 215kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 225kB 19.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 235kB 19.2MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 245kB 19.2MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 256kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 266kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 276kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 286kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 296kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 307kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 317kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 327kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 337kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 348kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 358kB 19.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 368kB 19.2MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 378kB 19.2MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 389kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 399kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 409kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 419kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 430kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 440kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 450kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 460kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 471kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 481kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 491kB 19.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 501kB 19.2MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 512kB 19.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 522kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 532kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 542kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 552kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 563kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 573kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 583kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 593kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 604kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 614kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 624kB 19.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 634kB 19.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 645kB 19.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 655kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 665kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 675kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 686kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 696kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 706kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 716kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 727kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 737kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 747kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 757kB 19.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 768kB 19.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 778kB 19.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 788kB 19.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 798kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 808kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 819kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 829kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 839kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 849kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 860kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 870kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 880kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 890kB 19.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 901kB 19.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 911kB 19.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 921kB 19.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 931kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 942kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 952kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 962kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 972kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 983kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 993kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 19.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.0MB 19.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.0MB 19.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.0MB 19.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.0MB 19.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1MB 19.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1MB 19.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 19.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (1.13.4)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 25.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (1.18.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 25.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.6.0) (2019.12.20)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.6.0) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.6.0) (1.16.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.6.0) (0.3.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.6.0) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.6.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.6.0) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.6.0) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.6.0) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.6.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.6.0) (0.14.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.4->boto3->transformers==2.6.0) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.4->boto3->transformers==2.6.0) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=d946f20e34313d19cffb8a31c71bb0fa283adcdc7adf87647124d89907f8b465\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.90 tokenizers-0.5.2 transformers-2.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egqq-nMHYtDG",
        "colab_type": "code",
        "outputId": "9840ce7e-31bc-4c2a-c607-856b48991a0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "!pip install fairseq"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fairseq\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/bf/de299e082e7af010d35162cb9a185dc6c17db71624590f2f379aeb2519ff/fairseq-0.9.0.tar.gz (306kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.17)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.18.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq) (2019.12.20)\n",
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/9d/9846507837ca50ae20917f59d83b79246b8313bd19d4f5bf575ecb98132b/sacrebleu-1.4.9-py3-none-any.whl (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.5.0+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq) (4.41.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.20)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu->fairseq) (3.6.6)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (0.16.0)\n",
            "Building wheels for collected packages: fairseq\n",
            "  Building wheel for fairseq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.9.0-cp36-cp36m-linux_x86_64.whl size=2035365 sha256=bedcca73601b0137b150bd46512eb81e629363c480e872af83de92ea963dc595\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/3e/1b/0fa30695dcba41e4b0088067fa40f3328d1e8ee78c22cd4766\n",
            "Successfully built fairseq\n",
            "Installing collected packages: portalocker, sacrebleu, fairseq\n",
            "Successfully installed fairseq-0.9.0 portalocker-1.7.0 sacrebleu-1.4.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxPmfRKEYvWM",
        "colab_type": "code",
        "outputId": "9e19383b-8df8-4ee2-f3fd-df6a21b4cc62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "!pip install fastBPE"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastBPE\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/37/f97181428a5d151501b90b2cebedf97c81b034ace753606a3cda5ad4e6e2/fastBPE-0.1.0.tar.gz\n",
            "Building wheels for collected packages: fastBPE\n",
            "  Building wheel for fastBPE (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastBPE: filename=fastBPE-0.1.0-cp36-cp36m-linux_x86_64.whl size=479246 sha256=c7220b03b25dd05935ba7b5f0d5810a621e113470a8f5d6c87066788c8501595\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/0c/9c/fc62058b4d473a5602bcd3d3edfece796f123875379ea82d79\n",
            "Successfully built fastBPE\n",
            "Installing collected packages: fastBPE\n",
            "Successfully installed fastBPE-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZBCwr9NdWhS",
        "colab_type": "code",
        "outputId": "d3f9e00a-32b1-44e7-b971-515b2ca24531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.4)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.3.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=33b2b9104c8d311c335e3e27419dbcc91eae8c4efaef45874d3de710236b2328\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-0.0.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6xCcDtbY3f0",
        "colab_type": "code",
        "outputId": "c9ceccc8-c0f3-4a17-e1b5-8a079059049a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "import argparse\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import transformers\n",
        "import pandas as pd\n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, RandomSampler, TensorDataset, SequentialSampler\n",
        "\n",
        "from fairseq.data.encoders.fastbpe import fastBPE\n",
        "from fairseq.data import Dictionary\n",
        "\n",
        "from transformers import RobertaConfig, RobertaForTokenClassification\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.notebook import trange\n",
        "from seqeval.metrics import f1_score"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdv00jsYfhd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHPeu0KffDOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 60\n",
        "batch_sz = 16\n",
        "epochs = 5\n",
        "max_grad_norm = 1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TpMivmBw95V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "print('{}: {}'.format(device, n_gpu))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrQh9wLOfJpC",
        "colab_type": "text"
      },
      "source": [
        "#Load Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EO5x0SxoorZ",
        "colab_type": "text"
      },
      "source": [
        "**Read Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcgSUnfPfIxT",
        "colab_type": "code",
        "outputId": "f4eb7cc7-255d-497a-b9bc-72e0b5b95823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/data/ner_products_bio.csv', header=None,\n",
        "                   sep='\\t', encoding='utf8', names=['Sentence#', 'Word', 'Tag'])\n",
        "data.head(10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence#</th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Nhưng</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>hiện_tại</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>bạn</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>đang</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>cho</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>bé</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>bú</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>nên</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>bạn</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>không</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentence#      Word Tag\n",
              "0          1     Nhưng   O\n",
              "1          1  hiện_tại   O\n",
              "2          1       bạn   O\n",
              "3          1      đang   O\n",
              "4          1       cho   O\n",
              "5          1        bé   O\n",
              "6          1        bú   O\n",
              "7          1       nên   O\n",
              "8          1       bạn   O\n",
              "9          1     không   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZZOEJcNioYq",
        "colab_type": "code",
        "outputId": "f5728fb3-3a3c-49ce-a72a-280377f9ddeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "tuple_func = lambda f: [(w, t) for w, t in zip(f['Word'].values, f['Tag'].values)]\n",
        "sentences_with_tag = data.groupby('Sentence#').apply(tuple_func)\n",
        "print(sentences_with_tag)\n",
        "sentences_with_tag = [sent for sent in sentences_with_tag]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence#\n",
            "1       [(Nhưng, O), (hiện_tại, O), (bạn, O), (đang, O...\n",
            "2                        [(Áo, B-pr), (Hm, I-pr), (ạ, O)]\n",
            "3       [(Cho, O), (mình, O), (đặt, O), (cái, O), (bal...\n",
            "4       [(Ac, O), (có, O), (vest, B-pr), (chưa, O), (?...\n",
            "5       [(body, B-pr), (lotion, I-pr), (e, O), (lại, O...\n",
            "                              ...                        \n",
            "2517    [(Mình, O), (có, O), (s10, B-pr), (plus, I-pr)...\n",
            "2518    [(Shop, O), (còn, O), (cho, O), (đổi, O), (Sam...\n",
            "2519    [(Đã, O), (bao_gồm, O), (trợ_giá, O), (với, O)...\n",
            "2520    [(Chỉ, O), (nứt, O), (một, O), (đường, O), (tr...\n",
            "2521    [(Lúc, O), (sáng, O), (e, O), (có, O), (hỏi, O...\n",
            "Length: 2521, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r60imrFdkOpJ",
        "colab_type": "code",
        "outputId": "fbc24ff4-6f94-4846-ad35-d6f5603ad539",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sentences = [' '.join([word[0] for word in sent]) for sent in sentences_with_tag]\n",
        "sentences[1]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Áo Hm ạ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv4hl9q1kpLq",
        "colab_type": "code",
        "outputId": "5428594b-0047-412a-d26e-eb24f37cea7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "labels = [[word[1] for word in sent] for sent in sentences_with_tag]\n",
        "labels[1]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-pr', 'I-pr', 'O']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYmGJG8wk_MM",
        "colab_type": "code",
        "outputId": "3cfaa7e2-e651-41da-c036-e4ac3d72eeee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "labels_value = ['B-pr','I-pr','O', 'PAD', '[CLS]', '[SEP]', 'X']\n",
        "label2idx = {label:indx for indx, label in enumerate(labels_value)}\n",
        "label2idx"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-pr': 0, 'I-pr': 1, 'O': 2, 'PAD': 3, 'X': 6, '[CLS]': 4, '[SEP]': 5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq7o6689grKS",
        "colab_type": "text"
      },
      "source": [
        "***Encode with bpe***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRffu0CnmGZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--bpe-codes', \n",
        "    default=\"/content/drive/My Drive/pre_model/phobert/PhoBERT_base_transformers/bpe.codes\",\n",
        "    required=False,\n",
        "    type=str,  \n",
        "    help='path to fastBPE BPE'\n",
        ")\n",
        "args, unknown = parser.parse_known_args()\n",
        "\n",
        "bpe = fastBPE(args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FchxuuOUmgd5",
        "colab_type": "code",
        "outputId": "1767b9cf-2a3b-4210-b0df-760f99016a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "subwords = ['<s> '+bpe.encode(sent)+' </s>' for sent in sentences]\n",
        "subwords[1] "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> Áo H@@ m ạ </s>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ65kPhdnS3k",
        "colab_type": "code",
        "outputId": "09658b25-e58f-4149-f29b-f4ac167f1422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plt.hist([len(s.split()) for s in subwords])\n",
        "plt.xlabel('Number of word')\n",
        "plt.ylabel('Number of sentences')\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaS_WRMKoPz9",
        "colab_type": "text"
      },
      "source": [
        "***Change labels by subword***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY3O9SFPn2lQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_subwords = []\n",
        "for i in range(len(subwords)):\n",
        "  indx = 0\n",
        "  label = ['[CLS]']\n",
        "  for word in subwords[i].split()[1:MAX_LEN-1]:\n",
        "    if word == '</s>':\n",
        "      break\n",
        "    if '@@' not in word:\n",
        "      label.append(labels[i][indx])\n",
        "      indx += 1\n",
        "      continue\n",
        "    label.append('X')\n",
        "  label.append('[SEP]')\n",
        "  label_subwords.append(label) \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJWHuchWyRd6",
        "colab_type": "code",
        "outputId": "b1854802-ce72-473f-d1b6-6d1310c0fc4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "label_subwords[1]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]', 'B-pr', 'X', 'I-pr', 'O', '[SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnoorgFJhvav",
        "colab_type": "text"
      },
      "source": [
        "***String to number***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtM9Wg6kmeMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Dictionary()\n",
        "vocab.add_from_file(\"/content/drive/My Drive/pre_model/phobert/PhoBERT_large_transformers/dict.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj3CxWSknK4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = pad_sequences([vocab.encode_line(sent, append_eos=False, add_if_not_exist=False).long().tolist() for sent in subwords],\n",
        "                          truncating='post', padding='post', maxlen=MAX_LEN, value=1.0, dtype='long')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spjCT1eljz6v",
        "colab_type": "code",
        "outputId": "192f0aad-e527-4784-b728-192c663a2cf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "input_ids[1]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0, 3759, 1125,  599, 3628,    2,    1,    1,    1,    1,    1,\n",
              "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "          1,    1,    1,    1,    1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGiwadUIkHLU",
        "colab_type": "code",
        "outputId": "a556b7fc-18b8-4409-83ee-c86622bf270f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "labels_ids = pad_sequences([[label2idx.get(label) for label in labels] for labels in label_subwords], dtype='long',\n",
        "                            maxlen=MAX_LEN, value=label2idx['PAD'], truncating='post', padding='post')\n",
        "labels_ids[1]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 0, 6, 1, 2, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f6nNRWHlNbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attenion_mask = [[float(val != 1) for val in sent] for sent in input_ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5ajISqfmBUF",
        "colab_type": "text"
      },
      "source": [
        "***Create train/validation data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JteRr4K7l6rw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(input_ids, labels_ids, random_state=96, test_size=0.2)\n",
        "train_mask, val_mask, _, _ = train_test_split(attenion_mask, input_ids, random_state=96, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e6zMj1im3Zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change to tensor\n",
        "X_train = torch.tensor(X_train)\n",
        "X_val = torch.tensor(X_val)\n",
        "y_train = torch.tensor(y_train)\n",
        "y_val = torch.tensor(y_val)\n",
        "train_mask = torch.tensor(train_mask)\n",
        "val_mask = torch.tensor(val_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQHBYd-vnTiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create data loader\n",
        "train_data = TensorDataset(X_train, train_mask, y_train)\n",
        "train_sample = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sample, batch_size=batch_sz)\n",
        "\n",
        "val_data = TensorDataset(X_val, val_mask, y_val)\n",
        "val_sample = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sample, batch_size=batch_sz)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9kIr1uRopx_",
        "colab_type": "code",
        "outputId": "4e749b83-2bea-4a2e-9a82-19e091dc9721",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "val_data[1]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([    0, 13072,    68,   202,   188, 27481,  1187, 15654,     2,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]),\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0.]),\n",
              " tensor([4, 2, 2, 2, 2, 6, 6, 0, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMlEkVv_qP3N",
        "colab_type": "text"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqIBBDftqU5c",
        "colab_type": "text"
      },
      "source": [
        "***Load pretrained model PhoBert(large)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vFvMGKsqFrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = RobertaConfig.from_pretrained(\n",
        "    \"/content/drive/My Drive/pre_model/phobert/PhoBERT_base_transformers/config.json\",\n",
        "    num_labels=len(label2idx)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3NclR75qcj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = RobertaForTokenClassification.from_pretrained(\n",
        "    \"/content/drive/My Drive/pre_model/phobert/PhoBERT_base_transformers/model.bin\",\n",
        "    config=config\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nFbgfC3qpRE",
        "colab_type": "code",
        "outputId": "f6a17ce4-602f-4024-acb1-8868833675c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# pass model parameter to GPU\n",
        "model.cuda()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForTokenClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foDkfN9vqsuU",
        "colab_type": "text"
      },
      "source": [
        "***Add optimizer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD3h4YHJqqzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.0}\n",
        "]\n",
        "optimizer = AdamW(\n",
        "    optimizer_grouped_parameters,\n",
        "    lr=3e-5,\n",
        "    eps=1e-8\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOvsF0rjuCgg",
        "colab_type": "text"
      },
      "source": [
        "***Add a scheduler to linearly reduce the learning rate throughout the epochs***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMRZMD6cr96X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_steps = len(train_dataloader)*epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKGguI5MwRQX",
        "colab_type": "text"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqMPxWvqpCj2",
        "colab_type": "code",
        "outputId": "dca1ef01-c7d0-48f7-c7b0-a9c71cec696f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404,
          "referenced_widgets": [
            "1c5ee89a77ed425180a1fc11c12c4c4d",
            "e5f2bbd51ba7487dbb4b2f2c6ece4635",
            "9a5cf02acb084c919feb9a186b205dc4",
            "c2eb890c8028485d8a96cc9f8a5d504c",
            "d8205c9452f74b1d80abc3859941cb31",
            "201b144a67a743d09a8cb0d7ca641998",
            "9fdaa26b78a14ad08e90eb664281bca3",
            "e4f71ede9622408c8ad7ae8d55e3c71a"
          ]
        }
      },
      "source": [
        "for epoch in trange(epochs, desc='Epoch'):\n",
        "  \n",
        "  # TRAIN\n",
        "  \n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  for batch in train_dataloader:\n",
        "    # add to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    X_train, train_mask, y_train = batch\n",
        "\n",
        "    # clear gradient after each backward\n",
        "    model.zero_grad()\n",
        "\n",
        "    # get loss and score\n",
        "    output = model(X_train, attention_mask=train_mask, labels=y_train)\n",
        "\n",
        "    loss = output[0]\n",
        "    loss.backward()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    \n",
        "    # norm gradient\n",
        "    torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "    \n",
        "    # update parameter\n",
        "    optimizer.step()\n",
        "    # update learning rate\n",
        "    scheduler.step()\n",
        "  \n",
        "  print('Average train loss: {}'.format(total_loss/len(train_dataloader)))\n",
        "\n",
        "  # VALIDATION\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  pred_labels_ids, true_labels_ids, val_ids_sent = [], [], []\n",
        "  for batch in val_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    X_val, val_mask, y_val = batch\n",
        "\n",
        "    # return (score)\n",
        "    with torch.no_grad():\n",
        "      output_val = model(X_val, val_mask)\n",
        "    \n",
        "    # move to CPU\n",
        "    val_ids_sent.extend(X_val)\n",
        "    logit = output_val[0].detach().cpu().numpy()\n",
        "    label_ids = y_val.to('cpu').numpy()\n",
        "\n",
        "    pred_labels_ids.extend([list(pred_label) for pred_label in np.argmax(logit, axis=2)])\n",
        "    true_labels_ids.extend(label_ids)\n",
        "  \n",
        "  # dont use PAD labels to compute f1 score\n",
        "  pred_labels = [labels_value[pred_indx] for pred, true in zip(pred_labels_ids, true_labels_ids)\n",
        "                                      for pred_indx, true_indx in zip(pred, true) if labels_value[true_indx] != 'PAD']\n",
        "  true_labels = [labels_value[indx] for true in true_labels_ids\n",
        "                                      for indx in true if labels_value[indx] != 'PAD']\n",
        "  print('{}. Validation F1-score: {}\\n'.format(epoch+1, f1_score(pred_labels, true_labels)))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c5ee89a77ed425180a1fc11c12c4c4d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=5.0, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average train loss: 0.5194902985933281\n",
            "1. Validation F1-score: 0.9168962350780532\n",
            "\n",
            "Average train loss: 0.16675413772463799\n",
            "2. Validation F1-score: 0.9236250278334447\n",
            "\n",
            "Average train loss: 0.11863017969188236\n",
            "3. Validation F1-score: 0.9309336332958381\n",
            "\n",
            "Average train loss: 0.09269856785734494\n",
            "4. Validation F1-score: 0.9280928986154533\n",
            "\n",
            "Average train loss: 0.07653087225284368\n",
            "5. Validation F1-score: 0.9295964125560537\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhXBySlHfyJm",
        "colab_type": "text"
      },
      "source": [
        "#Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmNPQRujf2OZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_subwords = []\n",
        "for sent in val_ids_sent:\n",
        "  val_subwords.extend(('<s> '+ vocab.string(sent) + ' </s>').replace('<pad>', '').split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phk8B67L6rPg",
        "colab_type": "code",
        "outputId": "f09f0aeb-e115-4697-cc47-598f3f7c771b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "list(zip(true_labels, pred_labels, val_subwords))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'dạ'),\n",
              " ('O', 'O', 'máy'),\n",
              " ('O', 'O', 'bao_gồm'),\n",
              " ('B-pr', 'O', 'máy'),\n",
              " ('I-pr', 'O', 'phím'),\n",
              " ('I-pr', 'I-pr', 'sạc'),\n",
              " ('O', 'I-pr', 'like'),\n",
              " ('O', 'I-pr', 'new'),\n",
              " ('O', 'O', 'shop'),\n",
              " ('O', 'O', 'tặng'),\n",
              " ('O', 'O', 'thêm'),\n",
              " ('O', 'B-pr', 'bao'),\n",
              " ('O', 'I-pr', 'da'),\n",
              " ('O', 'O', 'và'),\n",
              " ('O', 'B-pr', 'dán'),\n",
              " ('O', 'I-pr', 'lưng'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('O', 'O', 'máy'),\n",
              " ('X', 'X', 'b@@'),\n",
              " ('O', 'O', 'h'),\n",
              " ('O', 'O', '6'),\n",
              " ('O', 'O', 'tháng'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Dạ'),\n",
              " ('O', 'O', 'mình'),\n",
              " ('O', 'O', 'muốn'),\n",
              " ('O', 'O', 'mua'),\n",
              " ('X', 'X', 'kno@@'),\n",
              " ('X', 'X', 't@@'),\n",
              " ('B-pr', 'B-pr', 'ted'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('X', 'X', 'b@@'),\n",
              " ('X', 'X', 't@@'),\n",
              " ('B-pr', 'O', 'w'),\n",
              " ('I-pr', 'B-pr', 'bàn_phím'),\n",
              " ('X', 'X', 'us@@'),\n",
              " ('I-pr', 'I-pr', 'ed'),\n",
              " ('O', 'O', 'bên'),\n",
              " ('O', 'O', 'mình'),\n",
              " ('O', 'O', 'có'),\n",
              " ('O', 'O', 'ko'),\n",
              " ('O', 'O', 'bạn'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Chất'),\n",
              " ('B-pr', 'B-pr', 'áo'),\n",
              " ('O', 'O', 'ok'),\n",
              " ('O', 'O', 'b'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Nho'),\n",
              " ('I-pr', 'I-pr', 'sữa'),\n",
              " ('O', 'O', 'có'),\n",
              " ('O', 'O', 'thùng'),\n",
              " ('O', 'O', '2kg'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', 'e'),\n",
              " ('O', 'O', '?'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', '520'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', '/'),\n",
              " ('X', 'X', 'liệ@@'),\n",
              " ('X', 'X', 'u_tr@@'),\n",
              " ('X', 'X', 'ình_@@'),\n",
              " ('O', 'B-pr', 'viên'),\n",
              " ('O', 'I-pr', 'đặt'),\n",
              " ('X', 'X', 'Mon@@'),\n",
              " ('X', 'X', 'is@@'),\n",
              " ('X', 'X', 'ta@@'),\n",
              " ('B-pr', 'I-pr', 't'),\n",
              " ('O', 'O', 'của'),\n",
              " ('O', 'O', 'Mỹ'),\n",
              " ('O', 'O', 'đặc_trị'),\n",
              " ('O', 'O', 'nấm'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'O', 'Bộ'),\n",
              " ('I-pr', 'B-pr', 'dứa'),\n",
              " ('O', 'O', 'e'),\n",
              " ('O', 'O', 'lấy'),\n",
              " ('O', 'O', 'cho'),\n",
              " ('X', 'X', 's@@'),\n",
              " ('O', 'O', 'z'),\n",
              " ('O', 'O', 'lớn'),\n",
              " ('O', 'O', 'đi'),\n",
              " ('O', 'O', 'c'),\n",
              " ('O', 'O', 'để'),\n",
              " ('O', 'O', 'tết'),\n",
              " ('O', 'O', 'no'),\n",
              " ('O', 'O', 'mặc'),\n",
              " ('O', 'O', 'cung'),\n",
              " ('X', 'X', 'd@@'),\n",
              " ('O', 'O', 'c'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'C'),\n",
              " ('O', 'O', 'ơi'),\n",
              " ('O', 'O', 'ship'),\n",
              " ('O', 'O', 'e'),\n",
              " ('O', 'O', '3kg'),\n",
              " ('B-pr', 'B-pr', 'cam_sành'),\n",
              " ('O', 'O', 'đến'),\n",
              " ('O', 'O', '24'),\n",
              " ('O', 'O', 'minh'),\n",
              " ('O', 'O', 'khai'),\n",
              " ('O', 'O', 'với'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Chào'),\n",
              " ('O', 'O', 'bạn'),\n",
              " ('O', 'O', 'sản_phẩm'),\n",
              " ('O', 'O', 'bạn'),\n",
              " ('O', 'O', 'quan_tâm'),\n",
              " ('O', 'O', 'có'),\n",
              " ('O', 'O', 'giá'),\n",
              " ('O', 'O', '240.000'),\n",
              " ('O', 'O', '('),\n",
              " ('B-pr', 'O', 'ly'),\n",
              " ('O', 'O', ')'),\n",
              " ('O', 'O', 'hiện'),\n",
              " ('O', 'O', 'shop'),\n",
              " ('O', 'O', 'chỉ'),\n",
              " ('O', 'O', 'còn'),\n",
              " ('O', 'O', 'màu'),\n",
              " ('O', 'O', 'đen'),\n",
              " ('O', 'O', 'thôi'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', '1'),\n",
              " ('B-pr', 'O', 'thùng'),\n",
              " ('X', 'X', 'c@@'),\n",
              " ('I-pr', 'B-pr', '4'),\n",
              " ('O', 'I-pr', 'đen'),\n",
              " ('O', 'O', 'lon'),\n",
              " ('O', 'O', ')'),\n",
              " ('O', 'O', ')'),\n",
              " ('O', 'O', ')'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('X', 'X', 'Ser@@'),\n",
              " ('B-pr', 'B-pr', 'um'),\n",
              " ('I-pr', 'I-pr', 'tinh_chất'),\n",
              " ('I-pr', 'I-pr', 'nhau'),\n",
              " ('I-pr', 'I-pr', 'thai'),\n",
              " ('I-pr', 'I-pr', 'cừu'),\n",
              " ('X', 'X', 'Y@@'),\n",
              " ('I-pr', 'I-pr', 'HL'),\n",
              " ('O', 'O', 'được'),\n",
              " ('O', 'O', 'hàng'),\n",
              " ('O', 'O', 'triệu'),\n",
              " ('O', 'O', 'phụ_nữ'),\n",
              " ('O', 'O', 'tin_dùng'),\n",
              " ('O', 'O', 'bởi'),\n",
              " ('O', 'O', 'công_dụng'),\n",
              " ('O', 'O', 'rất'),\n",
              " ('O', 'O', 'tuyệt_vời'),\n",
              " ('O', 'O', 'làm'),\n",
              " ('O', 'O', 'mờ'),\n",
              " ('O', 'O', 'nám'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Nhưng'),\n",
              " ('O', 'O', 'hiện_tại'),\n",
              " ('O', 'O', 'bạn'),\n",
              " ('O', 'O', 'đang'),\n",
              " ('O', 'O', 'cho'),\n",
              " ('O', 'O', 'bé'),\n",
              " ('O', 'O', 'bú'),\n",
              " ('O', 'O', 'nên'),\n",
              " ('O', 'O', 'bạn'),\n",
              " ('O', 'O', 'không'),\n",
              " ('O', 'O', 'sử_dụng'),\n",
              " ('X', 'X', 'BH@@'),\n",
              " ('B-pr', 'B-pr', 'A'),\n",
              " ('O', 'O', 'được'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'B-pr', 'Sản_phẩm'),\n",
              " ('X', 'X', 'ret@@'),\n",
              " ('X', 'X', 'in@@'),\n",
              " ('B-pr', 'I-pr', 'ol'),\n",
              " ('O', 'O', 'bạn'),\n",
              " ('O', 'O', 'dùng'),\n",
              " ('O', 'O', 'tối'),\n",
              " ('O', 'O', 'nhé'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Mình'),\n",
              " ('O', 'O', 'cần'),\n",
              " ('O', 'O', 'mua'),\n",
              " ('O', 'O', 'một'),\n",
              " ('B-pr', 'B-pr', 'bộ'),\n",
              " ('I-pr', 'B-pr', 'sạc'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Dạ'),\n",
              " ('O', 'O', 'set'),\n",
              " ('O', 'O', 'full'),\n",
              " ('O', 'O', '3'),\n",
              " ('O', 'O', 'món'),\n",
              " ('X', 'X', 'V@@'),\n",
              " ('B-pr', 'B-pr', 'est'),\n",
              " ('X', 'X', '650@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', 'Set'),\n",
              " ('O', 'O', 'riêng'),\n",
              " ('B-pr', 'B-pr', 'áo_khoác'),\n",
              " ('O', 'O', 'và'),\n",
              " ('B-pr', 'B-pr', 'quần'),\n",
              " ('O', 'O', 'giá'),\n",
              " ('X', 'X', '4@@'),\n",
              " ('X', 'X', '95@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', 'có'),\n",
              " ('O', 'O', 'size'),\n",
              " ('O', 'O', 'S'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Mình'),\n",
              " ('O', 'O', 'mua'),\n",
              " ('X', 'X', 'sam@@'),\n",
              " ('B-pr', 'B-pr', 'sung'),\n",
              " ('I-pr', 'I-pr', 's'),\n",
              " ('I-pr', 'I-pr', '20'),\n",
              " ('I-pr', 'I-pr', '+'),\n",
              " ('O', 'O', 'được'),\n",
              " ('O', 'O', '2'),\n",
              " ('O', 'O', 'tuần'),\n",
              " ('O', 'O', 'muốn'),\n",
              " ('O', 'O', 'chuyển'),\n",
              " ('O', 'O', 'sang'),\n",
              " ('B-pr', 'B-pr', 'note'),\n",
              " ('I-pr', 'I-pr', '10'),\n",
              " ('I-pr', 'I-pr', '+'),\n",
              " ('O', 'O', 'thì'),\n",
              " ('O', 'O', 'như'),\n",
              " ('O', 'O', 'nào'),\n",
              " ('O', 'O', 'shop'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'cho'),\n",
              " ('O', 'O', 'mình'),\n",
              " ('O', 'O', 'hỏi'),\n",
              " ('X', 'X', 'j@@'),\n",
              " ('B-pr', 'B-pr', '7'),\n",
              " ('I-pr', 'I-pr', 'plus'),\n",
              " ('O', 'O', 'đổi'),\n",
              " ('B-pr', 'B-pr', 'note'),\n",
              " ('I-pr', 'I-pr', '10'),\n",
              " ('I-pr', 'I-pr', 'plus'),\n",
              " ('O', 'O', 'bù'),\n",
              " ('O', 'O', 'bao_nhiêu'),\n",
              " ('O', 'O', 'tiền'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'áo'),\n",
              " ('I-pr', 'I-pr', 'lông'),\n",
              " ('X', 'X', 'm@@'),\n",
              " ('O', 'O', 'ng'),\n",
              " ('O', 'O', 'chị'),\n",
              " ('O', 'O', 'ko'),\n",
              " ('O', 'O', 'cần'),\n",
              " ('O', 'O', 'rộng'),\n",
              " ('O', 'O', 'lắm'),\n",
              " ('O', 'O', 'đâu'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Shop'),\n",
              " ('O', 'O', 'thông_tin'),\n",
              " ('O', 'O', 'giúp'),\n",
              " ('O', 'O', 'ah'),\n",
              " ('O', 'O', '.'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'B-pr', 'Ben'),\n",
              " ('O', 'O', 'minh'),\n",
              " ('O', 'O', 'cơ'),\n",
              " ('B-pr', 'B-pr', 'rick'),\n",
              " ('X', 'X', 'ow@@'),\n",
              " ('I-pr', 'I-pr', 'en'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Dạ'),\n",
              " ('O', 'O', 'hàng'),\n",
              " ('O', 'O', 'bên'),\n",
              " ('O', 'O', 'em'),\n",
              " ('O', 'O', 'mới'),\n",
              " ('O', 'O', 'về'),\n",
              " ('O', 'O', 'date'),\n",
              " ('O', 'O', 'mới'),\n",
              " ('O', 'O', 'nhất'),\n",
              " ('O', 'O', 'luôn'),\n",
              " ('O', 'O', 'nha'),\n",
              " ('O', 'O', 'chị'),\n",
              " ('O', 'O', '4'),\n",
              " ('X', 'X', 'TH@@'),\n",
              " ('X', 'X', 'Ị@@'),\n",
              " ('B-pr', 'O', 'T'),\n",
              " ('X', 'X', 'H@@'),\n",
              " ('X', 'X', 'Ộ@@'),\n",
              " ('I-pr', 'O', 'P'),\n",
              " ('X', 'X', 'SP@@'),\n",
              " ('I-pr', 'I-pr', 'AM'),\n",
              " ('I-pr', 'O', '25'),\n",
              " ('X', 'X', 'LE@@'),\n",
              " ('I-pr', 'B-pr', 'SS'),\n",
              " ('X', 'X', 'SO@@'),\n",
              " ('X', 'X', 'DI@@'),\n",
              " ('I-pr', 'I-pr', 'UM'),\n",
              " ('X', 'X', '340@@'),\n",
              " ('I-pr', 'O', 'g'),\n",
              " ('O', 'O', 'giá'),\n",
              " ('X', 'X', '5@@'),\n",
              " ('X', 'X', '90@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'dạ'),\n",
              " ('O', 'O', '2'),\n",
              " ('B-pr', 'B-pr', 'áo'),\n",
              " ('O', 'O', 'này'),\n",
              " ('O', 'O', 'shop'),\n",
              " ('O', 'O', 'hết'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('X', 'X', 'Tr@@'),\n",
              " ('O', 'O', 'c'),\n",
              " ('O', 'O', 'đây'),\n",
              " ('O', 'O', 'thì'),\n",
              " ('O', 'O', 'sạc'),\n",
              " ('O', 'O', 'ở'),\n",
              " ('O', 'O', 'mức'),\n",
              " ('O', 'O', '10'),\n",
              " ('X', 'X', 'g@@'),\n",
              " ('O', 'O', 't'),\n",
              " ('O', 'O', '100'),\n",
              " ('O', 'O', 'chỉ'),\n",
              " ('O', 'O', 'mất'),\n",
              " ('X', 'X', '1@@'),\n",
              " ('X', 'X', 'h@@'),\n",
              " ('X', 'X', '5@@'),\n",
              " ('O', 'O', 'p'),\n",
              " ('O', 'O', '.'),\n",
              " ('O', 'O', ')'),\n",
              " ('X', 'X', 'n@@'),\n",
              " ('X', 'X', 'b@@'),\n",
              " ('O', 'O', 'sp'),\n",
              " ('O', 'O', 'Phản_hồi'),\n",
              " ('O', 'O', 'qua'),\n",
              " ('X', 'X', 'z@@'),\n",
              " ('O', 'O', 'alo'),\n",
              " ('X', 'X', '09@@'),\n",
              " ('X', 'X', 'xxxx@@'),\n",
              " ('X', 'X', 'x@@'),\n",
              " ('O', 'O', '206'),\n",
              " ('O', 'O', 'giúp'),\n",
              " ('O', 'O', 'em'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Váy'),\n",
              " ('O', 'O', 'giá'),\n",
              " ('X', 'X', '7@@'),\n",
              " ('X', 'X', '99@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', 'b'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Mà'),\n",
              " ('O', 'O', 'cái'),\n",
              " ('B-pr', 'B-pr', 'áo'),\n",
              " ('O', 'O', 'e'),\n",
              " ('O', 'O', 'để'),\n",
              " ('O', 'O', 'ở'),\n",
              " ('O', 'O', 'địa_chỉ'),\n",
              " ('O', 'O', 'nào'),\n",
              " ('O', 'O', 'vậy'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Xả'),\n",
              " ('O', 'O', 'kho'),\n",
              " ('X', 'X', 'sur@@'),\n",
              " ('B-pr', 'I-pr', 'face'),\n",
              " ('I-pr', 'I-pr', 'pro'),\n",
              " ('I-pr', 'I-pr', '6'),\n",
              " ('O', 'O', 'giá'),\n",
              " ('O', 'O', 'nhiêu'),\n",
              " ('O', 'O', 'bạn'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Bên'),\n",
              " ('O', 'O', 'em'),\n",
              " ('O', 'O', 'có'),\n",
              " ('O', 'O', 'mẫu'),\n",
              " ('B-pr', 'B-pr', 'uỷ'),\n",
              " ('I-pr', 'I-pr', 'tê'),\n",
              " ('O', 'O', 'nào'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Tạm_biệt'),\n",
              " ('O', 'O', 'vết'),\n",
              " ('O', 'O', 'thâm'),\n",
              " ('O', 'I-pr', 'nám'),\n",
              " ('O', 'O', 'với'),\n",
              " ('O', 'O', 'sản_phẩm'),\n",
              " ('X', 'X', 'Tinh_@@'),\n",
              " ('O', 'B-pr', 'chất'),\n",
              " ('O', 'O', 'điều_trị'),\n",
              " ('O', 'O', 'độc_đáo'),\n",
              " ('O', 'O', 'của'),\n",
              " ('X', 'X', 'Paul@@'),\n",
              " ('O', 'B-pr', 'a'),\n",
              " ('O', 'I-pr', 's'),\n",
              " ('X', 'X', 'Cho@@'),\n",
              " ('O', 'I-pr', 'ice'),\n",
              " ('O', 'O', 'với'),\n",
              " ('O', 'O', 'thành_phần'),\n",
              " ('O', 'O', 'hiệu_quả'),\n",
              " ('O', 'O', '1'),\n",
              " ('X', 'X', 'Ret@@'),\n",
              " ('X', 'X', 'in@@'),\n",
              " ('B-pr', 'B-pr', 'ol'),\n",
              " ('O', 'O', '.'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'còn'),\n",
              " ('X', 'X', 'b@@'),\n",
              " ('B-pr', 'B-pr', 'p'),\n",
              " ('O', 'O', 'này'),\n",
              " ('O', 'O', 'ko'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Phải'),\n",
              " ('O', 'O', 'mua'),\n",
              " ('B-pr', 'B-pr', 'thuốc'),\n",
              " ('I-pr', 'I-pr', 'kích'),\n",
              " ('I-pr', 'I-pr', 'rễ'),\n",
              " ('O', 'O', 'à'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'B-pr', 'á'),\n",
              " ('X', 'X', 'o_@@'),\n",
              " ('B-pr', 'B-pr', 'phông'),\n",
              " ('O', 'O', 'đang'),\n",
              " ('O', 'O', 'sale'),\n",
              " ('O', 'O', 'còn'),\n",
              " ('X', 'X', '100@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', '1'),\n",
              " ('O', 'O', 'cái'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'E'),\n",
              " ('O', 'O', 'ơi'),\n",
              " ('B-pr', 'B-pr', 'Hoa'),\n",
              " ('O', 'I-pr', 'nhà'),\n",
              " ('O', 'O', 'mình'),\n",
              " ('O', 'O', 'Hàn_Quốc'),\n",
              " ('O', 'O', 'hay'),\n",
              " ('B-pr', 'B-pr', 'Hoa'),\n",
              " ('X', 'X', '_T@@'),\n",
              " ('O', 'I-pr', 'q'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Mỗi'),\n",
              " ('O', 'O', 'cái'),\n",
              " ('B-pr', 'B-pr', 'khẩu_trang'),\n",
              " ('X', 'X', 'n@@'),\n",
              " ('X', 'X', 't@@'),\n",
              " ('O', 'O', 'n'),\n",
              " ('O', 'O', 'thì'),\n",
              " ('O', 'O', 'giặt'),\n",
              " ('O', 'O', 'đc'),\n",
              " ('X', 'X', 'b@@'),\n",
              " ('O', 'O', 'n'),\n",
              " ('O', 'O', 'lần'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('X', 'X', 'S@@'),\n",
              " ('O', 'B-pr', 'dt'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'M'),\n",
              " ('O', 'O', 'mua'),\n",
              " ('B-pr', 'B-pr', 'sữa'),\n",
              " ('I-pr', 'I-pr', 'rửa'),\n",
              " ('I-pr', 'I-pr', 'mặt'),\n",
              " ('O', 'O', 'cơ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'giá'),\n",
              " ('O', 'O', '39'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', '/'),\n",
              " ('O', 'O', 'kg'),\n",
              " ('O', 'O', 'là'),\n",
              " ('O', 'O', 'giá'),\n",
              " ('B-pr', 'B-pr', 'lê'),\n",
              " ('O', 'O', '_'),\n",
              " ('X', 'X', 'nam_@@'),\n",
              " ('B-pr', 'B-pr', 'phi'),\n",
              " ('O', 'O', 'c'),\n",
              " ('O', 'O', 'nhé'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'váy'),\n",
              " ('I-pr', 'I-pr', 'nhẹ_nhàng'),\n",
              " ('O', 'O', 'cho'),\n",
              " ('O', 'O', 'mẹ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Chị'),\n",
              " ('O', 'O', 'muốn'),\n",
              " ('O', 'O', 'lấy'),\n",
              " ('X', 'X', 'pedi@@'),\n",
              " ('X', 'X', 'aki@@'),\n",
              " ('B-pr', 'B-pr', 'd'),\n",
              " ('O', 'O', 'ăn'),\n",
              " ('O', 'O', 'ngon'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Set'),\n",
              " ('O', 'O', 'này'),\n",
              " ('O', 'O', 'và'),\n",
              " ('B-pr', 'B-pr', 'quần'),\n",
              " ('O', 'O', 'này'),\n",
              " ('O', 'O', 'bé'),\n",
              " ('X', 'X', '5@@'),\n",
              " ('O', 'O', 'T'),\n",
              " ('O', 'O', 'sale'),\n",
              " ('O', 'O', 'còn'),\n",
              " ('X', 'X', 'b@@'),\n",
              " ('X', 'X', 'nh@@'),\n",
              " ('O', 'O', 'iu'),\n",
              " ('O', 'O', 'vậy'),\n",
              " ('O', 'O', 'shop'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Về'),\n",
              " ('O', 'O', 'hiệu_năng'),\n",
              " ('O', 'O', 'cũng'),\n",
              " ('O', 'O', 'như'),\n",
              " ('O', 'B-pr', 'pin'),\n",
              " ('O', 'O', '.'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'The'),\n",
              " ('X', 'X', 'pl@@'),\n",
              " ('X', 'X', 'ac@@'),\n",
              " ('I-pr', 'I-pr', 'enta'),\n",
              " ('X', 'X', 'vi@@'),\n",
              " ('O', 'I-pr', 'en'),\n",
              " ('O', 'O', 'còn'),\n",
              " ('O', 'O', 'ko'),\n",
              " ('O', 'O', 'c'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Baby'),\n",
              " ('X', 'X', 'flo@@'),\n",
              " ('I-pr', 'I-pr', 'at'),\n",
              " ('O', 'O', '299'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', '/'),\n",
              " ('O', 'O', 'buổi'),\n",
              " ('O', 'O', '('),\n",
              " ('O', 'O', '45'),\n",
              " ('O', 'O', 'phút'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Váy'),\n",
              " ('I-pr', 'I-pr', 'hoa'),\n",
              " ('X', 'X', 'Vin@@'),\n",
              " ('I-pr', 'I-pr', 'tage'),\n",
              " ('O', 'O', 'giá'),\n",
              " ('X', 'X', '29@@'),\n",
              " ('X', 'X', '5@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('O', 'O', '.'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Cho'),\n",
              " ('O', 'O', 'mình'),\n",
              " ('O', 'O', 'hỏi'),\n",
              " ('O', 'O', 'là'),\n",
              " ('O', 'O', 'cửa_hàng'),\n",
              " ('O', 'O', 'hằng'),\n",
              " ('O', 'O', 'ngày'),\n",
              " ('O', 'O', 'có'),\n",
              " ('O', 'O', 'mở_cửa'),\n",
              " ('O', 'O', 'không'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'dạ'),\n",
              " ('O', 'O', 'hiện'),\n",
              " ('B-pr', 'B-pr', 'áo'),\n",
              " ('O', 'O', 'chưa'),\n",
              " ('O', 'O', 'đc'),\n",
              " ('O', 'O', 'bán'),\n",
              " ('O', 'O', 'ở'),\n",
              " ('O', 'O', 'shop'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Thêm'),\n",
              " ('O', 'O', 'c'),\n",
              " ('O', 'O', '1'),\n",
              " ('O', 'O', 'túi'),\n",
              " ('O', 'O', '4'),\n",
              " ('O', 'O', 'quả'),\n",
              " ('B-pr', 'B-pr', 'cam'),\n",
              " ('O', 'O', 'nữa'),\n",
              " ('O', 'O', 'nhé'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Khăn'),\n",
              " ('O', 'O', 'này'),\n",
              " ('X', 'X', 'b@@'),\n",
              " ('O', 'O', 'n'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'lựu'),\n",
              " ('I-pr', 'I-pr', 'đào'),\n",
              " ('I-pr', 'I-pr', 'mai'),\n",
              " ('O', 'O', 'liệu'),\n",
              " ('O', 'O', 'còn'),\n",
              " ('O', 'O', 'k'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'cho'),\n",
              " ('O', 'O', 'Chị'),\n",
              " ('O', 'O', '2'),\n",
              " ('O', 'O', 'ký'),\n",
              " ('B-pr', 'B-pr', 'nho'),\n",
              " ('I-pr', 'I-pr', 'mẫu_đơn'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'M'),\n",
              " ('O', 'O', 'cần'),\n",
              " ('B-pr', 'B-pr', 'dầu'),\n",
              " ('I-pr', 'I-pr', 'mọc'),\n",
              " ('I-pr', 'O', 'và'),\n",
              " ('I-pr', 'O', 'chống'),\n",
              " ('I-pr', 'O', 'rụng'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Tranh'),\n",
              " ('I-pr', 'I-pr', 'cá_voi'),\n",
              " ('I-pr', 'I-pr', 'vàng'),\n",
              " ('O', 'O', '3'),\n",
              " ('O', 'O', 'bức'),\n",
              " ('O', 'O', 'kích_thước'),\n",
              " ('O', 'O', 'và'),\n",
              " ('O', 'O', 'giá'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Mình'),\n",
              " ('O', 'O', '1'),\n",
              " ('B-pr', 'B-pr', 'chai'),\n",
              " ('X', 'X', 'rè@@'),\n",
              " ('I-pr', 'B-pr', 'ill'),\n",
              " ('O', 'O', 'shop'),\n",
              " ('O', 'O', 'ơi'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('X', 'X', 'Shor@@'),\n",
              " ('B-pr', 'B-pr', 't'),\n",
              " ('I-pr', 'I-pr', 'kaki'),\n",
              " ('O', 'O', 'có'),\n",
              " ('O', 'O', 'size'),\n",
              " ('O', 'O', 'gì'),\n",
              " ('O', 'O', 'ad'),\n",
              " ('O', 'O', '?'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Shop'),\n",
              " ('O', 'O', 'có'),\n",
              " ('O', 'O', 'giữ'),\n",
              " ('O', 'O', 'giấy_tờ'),\n",
              " ('O', 'O', 'khi'),\n",
              " ('O', 'O', 'tham_gia'),\n",
              " ('O', 'O', 'trả_góp'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'O', 'kẻ'),\n",
              " ('I-pr', 'O', 'mày'),\n",
              " ('I-pr', 'O', 'the'),\n",
              " ('I-pr', 'O', 'face'),\n",
              " ('O', 'O', 'shop'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('X', 'X', 'td@@'),\n",
              " ('B-pr', 'O', 'c'),\n",
              " ('X', 'X', '59@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', 'b'),\n",
              " ('O', 'O', 'nha'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Cho'),\n",
              " ('O', 'O', 'mình'),\n",
              " ('O', 'O', '3'),\n",
              " ('O', 'O', 'cái'),\n",
              " ('B-pr', 'B-pr', 'bơm'),\n",
              " ('O', 'O', 'đc'),\n",
              " ('O', 'O', 'ko'),\n",
              " ('O', 'O', '?'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('X', 'X', 'Pan@@'),\n",
              " ('X', 'X', 'ten@@'),\n",
              " ('B-pr', 'B-pr', 'e'),\n",
              " ('X', 'X', '120@@'),\n",
              " ('X', 'X', 'mo@@'),\n",
              " ('O', 'I-pr', 't'),\n",
              " ('O', 'O', 'chai'),\n",
              " ('O', 'O', 'hay'),\n",
              " ('X', 'X', 'mo@@'),\n",
              " ('O', 'O', 't'),\n",
              " ('O', 'O', 'cap'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Nhà'),\n",
              " ('O', 'O', 'm'),\n",
              " ('O', 'O', 'còn'),\n",
              " ('B-pr', 'B-pr', 'sữa'),\n",
              " ('X', 'X', 'me@@'),\n",
              " ('I-pr', 'I-pr', 'ji'),\n",
              " ('O', 'I-pr', 'lon'),\n",
              " ('O', 'O', '0'),\n",
              " ('O', 'O', '1'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Dạ'),\n",
              " ('O', 'O', 'em'),\n",
              " ('O', 'O', 'chào'),\n",
              " ('O', 'O', 'c'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('O', 'O', 'c'),\n",
              " ('O', 'O', 'hỏi'),\n",
              " ('O', 'O', 'mẫu'),\n",
              " ('O', 'O', 'nào'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('B-pr', 'B-pr', 'bảng'),\n",
              " ('I-pr', 'O', 'to'),\n",
              " ('O', 'O', 'hay'),\n",
              " ('B-pr', 'B-pr', 'bảng'),\n",
              " ('I-pr', 'I-pr', 'nhỏ'),\n",
              " ('O', 'O', 'màu'),\n",
              " ('O', 'O', 'vàng'),\n",
              " ('O', 'O', 'hay'),\n",
              " ('O', 'O', 'trắng'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Mình'),\n",
              " ('O', 'O', 'đem'),\n",
              " ('O', 'O', 'ra'),\n",
              " ('O', 'O', 'cửa_hàng'),\n",
              " ('X', 'X', 'n@@'),\n",
              " ('O', 'O', 'v'),\n",
              " ('O', 'O', 'kêu'),\n",
              " ('O', 'O', 'gửi'),\n",
              " ('O', 'O', 'máy'),\n",
              " ('O', 'O', 'thẩm_định'),\n",
              " ('O', 'O', '15'),\n",
              " ('O', 'O', 'ngày'),\n",
              " ('O', 'O', ','),\n",
              " ('O', 'O', 'mình'),\n",
              " ('O', 'O', 'nghĩ'),\n",
              " ('O', 'O', 'có_thể'),\n",
              " ('B-pr', 'O', 'cáp'),\n",
              " ('O', 'O', 'đã'),\n",
              " ('O', 'O', 'bị'),\n",
              " ('O', 'O', 'lỗi'),\n",
              " ('O', 'O', ','),\n",
              " ('O', 'O', 'thì'),\n",
              " ('O', 'O', 'làm'),\n",
              " ('O', 'O', 'cách'),\n",
              " ('O', 'O', 'nào'),\n",
              " ('O', 'O', 'để'),\n",
              " ('O', 'O', 'shop'),\n",
              " ('O', 'O', 'đổi'),\n",
              " ('B-pr', 'B-pr', 'cáp'),\n",
              " ('O', 'O', 'mới'),\n",
              " ('O', 'O', 'cho'),\n",
              " ('O', 'O', 'mình'),\n",
              " ('O', 'O', 'vì'),\n",
              " ('O', 'O', 'còn'),\n",
              " ('O', 'O', 'bảo_hành'),\n",
              " ('O', 'O', ','),\n",
              " ('O', 'O', 'cứ'),\n",
              " ('O', 'O', 'thẩm_định'),\n",
              " ('O', 'O', 'pin'),\n",
              " ('O', 'O', 'đến'),\n",
              " ('O', 'O', '15'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Michelin'),\n",
              " ('I-pr', 'I-pr', 'city'),\n",
              " ('X', 'X', 'gri@@'),\n",
              " ('I-pr', 'I-pr', 'p'),\n",
              " ('I-pr', 'I-pr', 'Pro'),\n",
              " ('X', 'X', '100@@'),\n",
              " ('X', 'X', '/@@'),\n",
              " ('O', 'O', '80'),\n",
              " ('O', 'O', '17'),\n",
              " ('O', 'O', 'giá'),\n",
              " ('O', 'O', '800'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Nhà'),\n",
              " ('O', 'O', 'còn'),\n",
              " ('O', 'B-pr', 'chả'),\n",
              " ('O', 'I-pr', 'mực'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', 'e'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('X', 'X', 'Đ@@'),\n",
              " ('O', 'O', 'k'),\n",
              " ('O', 'O', 'mua'),\n",
              " ('B-pr', 'O', 'máy'),\n",
              " ('O', 'O', 'trả_góp'),\n",
              " ('O', 'O', 'rồi'),\n",
              " ('O', 'O', 'khi'),\n",
              " ('O', 'O', 'ra'),\n",
              " ('O', 'O', 'nhận'),\n",
              " ('O', 'O', 'máy'),\n",
              " ('O', 'O', 'thì'),\n",
              " ('O', 'O', 'có_thể'),\n",
              " ('O', 'O', 'mang'),\n",
              " ('O', 'O', 'về'),\n",
              " ('O', 'O', 'nhà'),\n",
              " ('O', 'O', 'để'),\n",
              " ('O', 'O', 'tự'),\n",
              " ('O', 'O', 'khởi_động'),\n",
              " ('O', 'O', 'máy'),\n",
              " ('O', 'O', 'được'),\n",
              " ('O', 'O', 'không'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Bên'),\n",
              " ('O', 'O', 'mình'),\n",
              " ('O', 'O', 'còn'),\n",
              " ('B-pr', 'B-pr', 'ram'),\n",
              " ('I-pr', 'I-pr', 'DDR3'),\n",
              " ('I-pr', 'I-pr', '8g'),\n",
              " ('O', 'O', 'k'),\n",
              " ('X', 'X', 'ạ@@'),\n",
              " ('O', 'O', 'h'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'E'),\n",
              " ('O', 'O', 'muốn'),\n",
              " ('B-pr', 'B-pr', 'quần_bò'),\n",
              " ('I-pr', 'I-pr', 'đen'),\n",
              " ('I-pr', 'O', 'trơn'),\n",
              " ('X', 'X', 'bag@@'),\n",
              " ('I-pr', 'O', 'y'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Có'),\n",
              " ('O', 'O', 'thu'),\n",
              " ('O', 'O', 'cũ'),\n",
              " ('O', 'O', 'đổi_mới'),\n",
              " ('B-pr', 'B-pr', 'note'),\n",
              " ('I-pr', 'I-pr', '10'),\n",
              " ('I-pr', 'I-pr', 'lai'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Bên'),\n",
              " ('O', 'O', 'em'),\n",
              " ('O', 'O', 'về'),\n",
              " ('O', 'O', 'chỉ'),\n",
              " ('O', 'O', '100'),\n",
              " ('B-pr', 'B-pr', 'quần'),\n",
              " ('X', 'X', 'DUY@@'),\n",
              " ('X', 'X', '_@@'),\n",
              " ('O', 'O', 'NHẤT'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'V'),\n",
              " ('O', 'O', 'e'),\n",
              " ('O', 'O', 'lấy'),\n",
              " ('B-pr', 'B-pr', 'vòng'),\n",
              " ('I-pr', 'I-pr', 'cổ'),\n",
              " ('O', 'O', 'vs'),\n",
              " ('O', 'O', 'bộ'),\n",
              " ('B-pr', 'B-pr', 'bò_sữa'),\n",
              " ('X', 'X', 's@@'),\n",
              " ('O', 'O', 'z'),\n",
              " ('O', 'O', 'bé'),\n",
              " ('O', 'O', '8'),\n",
              " ('X', 'X', '9@@'),\n",
              " ('O', 'O', 'kg'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Đầm'),\n",
              " ('I-pr', 'I-pr', 'ngực'),\n",
              " ('O', 'O', '92'),\n",
              " ('O', 'O', 'eo'),\n",
              " ('O', 'O', '74'),\n",
              " ('O', 'O', 'dài'),\n",
              " ('O', 'O', '83'),\n",
              " ('O', 'O', 'bạn'),\n",
              " ('O', 'O', 'nhé'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Dạ'),\n",
              " ('O', 'O', 'shop'),\n",
              " ('O', 'O', 'ơi'),\n",
              " ('O', 'O', 'máy'),\n",
              " ('O', 'O', 'em'),\n",
              " ('O', 'O', 'mua'),\n",
              " ('O', 'O', 'xách'),\n",
              " ('O', 'O', 'tay'),\n",
              " ('O', 'O', 'bên'),\n",
              " ('O', 'O', 'mình'),\n",
              " ('O', 'O', 'có'),\n",
              " ('O', 'O', 'hỗ_trợ'),\n",
              " ('O', 'O', 'up'),\n",
              " ('O', 'O', 'room'),\n",
              " ('O', 'O', 'quốc_tế'),\n",
              " ('O', 'O', 'không'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'pin'),\n",
              " ('I-pr', 'I-pr', 'pro'),\n",
              " ('I-pr', 'I-pr', '5'),\n",
              " ('I-pr', 'O', '5'),\n",
              " ('O', 'O', 'tiếng'),\n",
              " ('O', 'O', 'a'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('O', 'O', 'cũng'),\n",
              " ('O', 'O', 'tuỳ'),\n",
              " ('O', 'O', 'vào'),\n",
              " ('O', 'O', 'các'),\n",
              " ('O', 'O', 'tab'),\n",
              " ('O', 'O', 'vụ'),\n",
              " ('O', 'O', 'anh'),\n",
              " ('X', 'X', 'l@@'),\n",
              " ('O', 'O', 'v'),\n",
              " ('O', 'O', 'nữa'),\n",
              " ('O', 'O', 'ạ'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'Tảo'),\n",
              " ('O', 'O', 'khi'),\n",
              " ('O', 'O', 'nào'),\n",
              " ('O', 'O', 'có'),\n",
              " ('O', 'O', 'hàng'),\n",
              " ('O', 'O', 'vậy'),\n",
              " ('O', 'O', 'shop'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'e'),\n",
              " ('O', 'O', 'lắp'),\n",
              " ('B-pr', 'B-pr', 'khoá'),\n",
              " ('I-pr', 'I-pr', 'bấm'),\n",
              " ('I-pr', 'I-pr', 'trắng'),\n",
              " ('O', 'O', 'cho'),\n",
              " ('O', 'O', 'a'),\n",
              " ('O', 'O', 'nhé'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('B-pr', 'B-pr', 'áo'),\n",
              " ('O', 'O', 'vs'),\n",
              " ('B-pr', 'B-pr', 'váy'),\n",
              " ('O', 'O', 'còn'),\n",
              " ('O', 'O', 'hàng'),\n",
              " ('O', 'O', 'ko'),\n",
              " ('O', 'O', 'bạn'),\n",
              " ('[SEP]', '[SEP]', '</s>'),\n",
              " ('[CLS]', '[CLS]', '<s>'),\n",
              " ('O', 'O', 'Cho'),\n",
              " ('O', 'O', 'mình'),\n",
              " ('O', 'O', 'thêm'),\n",
              " ('O', 'O', '1kg'),\n",
              " ('B-pr', 'B-pr', 'táo'),\n",
              " ('O', 'O', '1kg'),\n",
              " ('B-pr', 'B-pr', 'cam'),\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnFUKtkig0Ss",
        "colab_type": "text"
      },
      "source": [
        "*Model dự đoán gần như là chính xác hoàn toàn. Có những từ bị đánh label thiếu trong tập data, model cũng dự đoán được. Tuy nhiên model nhận dạng khá không đầy đủ tên của những sản phẩm có thuộc tính đi kèm, ví dụ:*\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "  True                      Predict\n",
        "\n",
        "Chuột logitech k dây --> Chuột logitech\n",
        "Đầm thun hoa dáng dài --> Đầm thun hoa\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk60B5uRZLw6",
        "colab_type": "text"
      },
      "source": [
        "#Save & load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymwxGm4rbtE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = '/content/drive/My Drive/pre_model/phobert/ner_product/model_base_state_dict.pt'\n",
        "labels_value = ['B-pr','I-pr','O', 'PAD', '[CLS]', '[SEP]', 'X']\n",
        "label2idx = {label:indx for indx, label in enumerate(labels_value)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqOOUeNnwtGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(),PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAHX6188hDeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import *\n",
        "\n",
        "class Ner(BertPreTrainedModel):\n",
        "    config_class = RobertaConfig\n",
        "    pretrained_model_archive_map = ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP\n",
        "    base_model_prefix = \"roberta\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "\n",
        "        self.roberta = RobertaModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "    ):\n",
        "\n",
        "        outputs = self.roberta(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "        )\n",
        "\n",
        "        sequence_output = outputs[0]\n",
        "\n",
        "        sequence_output = self.dropout(sequence_output)\n",
        "        logits = self.classifier(sequence_output)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_sba7lRcv66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = RobertaConfig.from_pretrained(\n",
        "    \"/content/drive/My Drive/pre_model/phobert/PhoBERT_base_transformers/config.json\",\n",
        "    num_labels=len(label2idx)\n",
        ")\n",
        "\n",
        "ner = Ner.from_pretrained(\n",
        "    \"/content/drive/My Drive/pre_model/phobert/PhoBERT_base_transformers/model.bin\",\n",
        "    config=config\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjblyC4Lbj67",
        "colab_type": "code",
        "outputId": "c52c63d8-2672-4b79-df7b-da5f68fff89b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "ner.load_state_dict(torch.load(PATH))\n",
        "ner.eval()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ner(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2HOIe277Vly",
        "colab_type": "text"
      },
      "source": [
        "#Test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOq-cl3zC817",
        "colab_type": "text"
      },
      "source": [
        "***Must use VnCoreNLP to tokenize before test***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Sf-gL-L7aKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sentence = 'Có chuột k dây logitech k ạ?'\n",
        "sent = '<s> ' + bpe.encode(test_sentence) +' </s>'\n",
        "sent_ids = vocab.encode_line(sent, append_eos=False, add_if_not_exist=False).long().tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6LCBRPK7fLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_sentence = pad_sequences([sent_ids], maxlen=MAX_LEN, dtype=\"long\", value=1.0, truncating=\"post\", padding=\"post\")\n",
        "input_ids = torch.tensor(tokenized_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMRn5tZd7z31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask = [[float(m != 1) for m in val] for val in input_ids]\n",
        "mask = torch.tensor(mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwc5Ji7m727W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    output = ner(input_ids, mask)\n",
        "label_ids = np.argmax(output[0].numpy(), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0-Qw0BdYfAT",
        "colab_type": "code",
        "outputId": "76670791-be2e-4927-fe12-4a2f9d0b6a99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "subword_label = list(zip([labels_value[label] for label in label_ids], sent.split()))\n",
        "subword_label"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('[CLS]', '<s>'),\n",
              " ('O', 'Có'),\n",
              " ('B-pr', 'chuột'),\n",
              " ('O', 'k'),\n",
              " ('B-pr', 'dây'),\n",
              " ('X', 'logi@@'),\n",
              " ('I-pr', 'tech'),\n",
              " ('O', 'k'),\n",
              " ('X', 'ạ@@'),\n",
              " ('O', '?'),\n",
              " ('[SEP]', '</s>')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx2d8MTsYz7c",
        "colab_type": "code",
        "outputId": "71d866d9-bdc8-4483-ed0d-87ef4af5154d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "sentence = []\n",
        "labels = []\n",
        "word = ''\n",
        "for label, sword in subword_label:\n",
        "  if '@@' not in sword:\n",
        "    word += sword\n",
        "    sentence.append(word)\n",
        "    labels.append(label)\n",
        "    word = ''\n",
        "    continue\n",
        "  word += sword.replace('@@', '')\n",
        "\n",
        "list(zip(sentence, labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<s>', '[CLS]'),\n",
              " ('Máy', 'B-pr'),\n",
              " ('samsung', 'B-pr'),\n",
              " ('note', 'I-pr'),\n",
              " ('10', 'I-pr'),\n",
              " ('plus', 'I-pr'),\n",
              " ('có', 'O'),\n",
              " ('giá', 'O'),\n",
              " ('là', 'O'),\n",
              " ('20.990.000', 'O'),\n",
              " ('đến', 'O'),\n",
              " ('bao_giờ', 'O'),\n",
              " ('vậy', 'O'),\n",
              " ('ạ', 'O'),\n",
              " ('</s>', '[SEP]')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1AuVZ-ymK3f",
        "colab_type": "code",
        "outputId": "971e21f8-291c-411f-9bdd-96ab9ce5cd82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Product perform by upper word\n",
        "sentence2string = ''\n",
        "for word, label in list(zip(sentence, labels))[1:len(sentence)-1]:\n",
        "  if label == 'O':\n",
        "    sentence2string += (word.lower() +' ')\n",
        "    continue\n",
        "  sentence2string += (word.upper() +' ')\n",
        "sentence2string"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'MÁY SAMSUNG NOTE 10 PLUS có giá là 20.990.000 đến bao_giờ vậy ạ '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsIWRj9Mw1HW",
        "colab_type": "text"
      },
      "source": [
        "#Load test\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX6aTV7fK_lr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PredictProduct:\n",
        "  def __init__(self):\n",
        "    self.vocab = self.load_vocab()\n",
        "    self.bpe = self.load_bpe()\n",
        "    self.data = self.load_data()\n",
        "  \n",
        "  def load_vocab(self):\n",
        "    vocab = Dictionary()\n",
        "    vocab.add_from_file(\"/content/drive/My Drive/pre_model/phobert/PhoBERT_large_transformers/dict.txt\")\n",
        "    \n",
        "    return vocab\n",
        "  \n",
        "  def load_bpe(self):\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--bpe-codes', \n",
        "      default=\"/content/drive/My Drive/pre_model/phobert/PhoBERT_base_transformers/bpe.codes\",\n",
        "      required=False,\n",
        "      type=str,  \n",
        "      help='path to fastBPE BPE'\n",
        "    )\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    bpe = fastBPE(args)\n",
        "\n",
        "    return bpe\n",
        "  \n",
        "  def load_data(self):\n",
        "    sents, sent_ids, masks = [], [], []\n",
        "    with open('/content/drive/My Drive/data/note.txt', encoding='utf8') as fr:\n",
        "      for line in fr:\n",
        "        sent = '<s> ' + self.bpe.encode(line) +' </s>'\n",
        "        sent2ids = self.vocab.encode_line(sent, append_eos=False, add_if_not_exist=False).long().tolist()\n",
        "        tokenized_sentence = pad_sequences([sent2ids], maxlen=MAX_LEN, dtype=\"long\", value=1.0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "        mask = [[float(m != 1) for m in val] for val in tokenized_sentence]\n",
        "\n",
        "        sents.append(sent)\n",
        "        sent_ids.append(tokenized_sentence)\n",
        "        masks.append(mask)\n",
        "\n",
        "    sent_ids = torch.tensor(sent_ids)\n",
        "    masks = torch.tensor(masks)\n",
        "    return (sents, sent_ids, masks)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAbYXU6q25zL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict = PredictProduct()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz4_Vam--miB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def get_predict(i):\n",
        "  with torch.no_grad():\n",
        "      output = ner(predict.data[1][i], predict.data[2][i])\n",
        "  label_ids = np.argmax(output[0].numpy(), axis=1)\n",
        "  subword_labels = list(zip([labels_value[label] for label in label_ids], predict.data[0][i].split()))\n",
        "  sentence = []\n",
        "  labels = []\n",
        "  word = ''\n",
        "  for label, sword in subword_labels:\n",
        "    if '@@' not in sword:\n",
        "      word += sword\n",
        "      sentence.append(word)\n",
        "      labels.append(label)\n",
        "      word = ''\n",
        "      continue\n",
        "    word += sword.replace('@@', '')\n",
        "\n",
        "  predict_sent = list(zip(sentence, labels))[1:-1]\n",
        "  return predict_sent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3DUR2Dw0qBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = open('note_label.txt', 'w+', encoding='utf8')\n",
        "for i in range(500, 1000):\n",
        "  for s, l in get_predict(i):\n",
        "    file.writelines(str(i)+'\\t'+s+'\\t'+l+'\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}